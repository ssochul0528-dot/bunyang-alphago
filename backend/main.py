from fastapi import FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Optional
import random
import datetime
import os
import uvicorn
import asyncio
from contextlib import asynccontextmanager
from sqlmodel import Field, Session, SQLModel, create_engine, select, or_, col
import logging
import httpx

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# --- Mock Data ---
MOCK_SITES = [
    {"id": "s1", "name": "íìŠ¤í…Œì´íŠ¸ íšŒë£¡ì—­ íŒŒí¬ë·°", "address": "ê²½ê¸°ë„ ì˜ì •ë¶€ì‹œ í˜¸ì›ë™ 281-21", "brand": "íìŠ¤í…Œì´íŠ¸", "category": "ì•„íŒŒíŠ¸", "price": 2417, "target_price": 2750, "supply": 1816, "status": "ì„ ì°©ìˆœ ê³„ì•½ ì¤‘"},
    {"id": "s12", "name": "ì˜ì •ë¶€ ë¡¯ë°ìºìŠ¬ ë‚˜ë¦¬ë²¡ì‹œí‹°", "address": "ê²½ê¸°ë„ ì˜ì •ë¶€ì‹œ ê¸ˆì˜¤ë™", "brand": "ë¡¯ë°ìºìŠ¬", "category": "ì•„íŒŒíŠ¸", "price": 2100, "target_price": 2300, "supply": 671, "status": "ë¯¸ë¶„ì–‘ ì”ì—¬ì„¸ëŒ€"},
    {"id": "s2", "name": "eí¸í•œì„¸ìƒ ë‚´í¬ í¼ìŠ¤íŠ¸ë“œë¦¼", "address": "ì¶©ì²­ë‚¨ë„ í™ì„±êµ° í™ë¶ì", "brand": "eí¸í•œì„¸ìƒ", "category": "ì•„íŒŒíŠ¸", "price": 1100, "target_price": 1300, "supply": 600, "status": "ì„ ì°©ìˆœ ë¶„ì–‘ ì¤‘"},
    {"id": "s3", "name": "ë§ˆí¬ ì—í”¼íŠ¸ ì–´ë°”ë‹‰", "address": "ì„œìš¸íŠ¹ë³„ì‹œ ë§ˆí¬êµ¬ ì•„í˜„ë™", "brand": "ì—í”¼íŠ¸", "category": "ì˜¤í”¼ìŠ¤í…”", "price": 4500, "target_price": 5200, "supply": 300, "status": "ì”ì—¬ì„¸ëŒ€ ë¶„ì–‘ ì¤‘"},
    {"id": "s4", "name": "ê°•ë‚¨ ë˜ë¯¸ì•ˆ ì›ë² ì¼ë¦¬", "address": "ì„œìš¸íŠ¹ë³„ì‹œ ì„œì´ˆêµ¬ ë°˜í¬ë™", "brand": "ë˜ë¯¸ì•ˆ", "category": "ì•„íŒŒíŠ¸", "price": 9500, "target_price": 11000, "supply": 2990, "status": "ì…ì£¼ ì§„í–‰ ì¤‘"},
    {"id": "s5", "name": "ì†¡ë„ ìì´ í’ê²½ì±„ ê·¸ë¼ë…¸ë¸”", "address": "ì¸ì²œê´‘ì—­ì‹œ ì—°ìˆ˜êµ¬ ì†¡ë„ë™", "brand": "ìì´", "category": "ì•„íŒŒíŠ¸", "price": 2500, "target_price": 2800, "supply": 3270, "status": "ì„ ì°©ìˆœ ë¶„ì–‘ ì¤‘"},
    {"id": "s6", "name": "ë™íƒ„ì—­ ëŒ€ë°© ì—˜ë¦¬ì›€ ë” ì‹œê·¸ë‹ˆì²˜", "address": "ê²½ê¸°ë„ í™”ì„±ì‹œ ì˜¤ì‚°ë™", "brand": "ëŒ€ë°©ì—˜ë¦¬ì›€", "category": "ì•„íŒŒíŠ¸", "price": 2200, "target_price": 2600, "supply": 464, "status": "ë¶„ì–‘ ì™„ë£Œ"},
    {"id": "s7", "name": "ìˆ˜ì§€êµ¬ì²­ì—­ ì›Œë„ˆë¹„ì´ë¸Œ", "address": "ê²½ê¸°ë„ ìš©ì¸ì‹œ ìˆ˜ì§€êµ¬ í’ë•ì²œë™", "brand": "ê¸°íƒ€", "category": "ì˜¤í”¼ìŠ¤í…”", "price": 3200, "target_price": 3500, "supply": 150, "status": "ì”ì—¬ì„¸ëŒ€ ì†Œì§„ ì¤‘"},
    {"id": "s8", "name": "í‰íƒ ë¸Œë ˆì¸ì‹œí‹° ì¤‘í¥S-í´ë˜ìŠ¤", "address": "ê²½ê¸°ë„ í‰íƒì‹œ ë„ì¼ë™", "brand": "ì¤‘í¥S-í´ë˜ìŠ¤", "category": "ì•„íŒŒíŠ¸", "price": 1500, "target_price": 1800, "supply": 1980, "status": "ì„ ì°©ìˆœ ê³„ì•½ ì¤‘"},
    {"id": "s9", "name": "ìš©ì¸ í‘¸ë¥´ì§€ì˜¤ ì›í´ëŸ¬ìŠ¤í„°", "address": "ê²½ê¸°ë„ ìš©ì¸ì‹œ ì²˜ì¸êµ¬ ë‚¨ë™", "brand": "í‘¸ë¥´ì§€ì˜¤", "category": "ì•„íŒŒíŠ¸", "price": 1800, "target_price": 2100, "supply": 1681, "status": "1ë‹¨ì§€ ë¶„ì–‘ ì¤‘"},
    {"id": "s10", "name": "ì˜¤ì‚°ì„¸êµ í•œì‹ ë”íœ´", "address": "ê²½ê¸°ë„ ì˜¤ì‚°ì‹œ ì„¸êµë™", "brand": "í•œì‹ ë”íœ´", "category": "ì•„íŒŒíŠ¸", "price": 1400, "target_price": 1650, "supply": 844, "status": "ì„ ì°©ìˆœ ë¶„ì–‘"},
    {"id": "s11", "name": "ì²œì•ˆ ì•„ì´íŒŒí¬ ì‹œí‹°", "address": "ì¶©ì²­ë‚¨ë„ ì²œì•ˆì‹œ ì„œë¶êµ¬ ì„±ì„±ë™", "brand": "ì•„ì´íŒŒí¬", "category": "ì•„íŒŒíŠ¸", "price": 1600, "target_price": 1900, "supply": 1126, "status": "ì²­ì•½ ì˜ˆì •"}
]

# --- Database Setup ---
sqlite_file_name = "database.db"
sqlite_url = f"sqlite:///{sqlite_file_name}"
engine = create_engine(sqlite_url, connect_args={"check_same_thread": False})

class Site(SQLModel, table=True):
    id: str = Field(primary_key=True)
    name: str
    address: str
    brand: Optional[str] = None
    category: str
    price: float
    target_price: float
    supply: int
    status: Optional[str] = None
    last_updated: datetime.datetime = Field(default_factory=datetime.datetime.now)
    
    __table_args__ = {"extend_existing": True}

def create_db_and_tables():
    logger.info("Initializing database...")
    try:
        SQLModel.metadata.create_all(engine)
        with Session(engine) as session:
            # Site í…Œì´ë¸”ì´ ë¹„ì–´ìˆëŠ” ê²½ìš°ì—ë§Œ ë°ì´í„° ì‚½ì…
            existing_site = session.exec(select(Site)).first()
            if not existing_site:
                logger.info("Populating mock sites...")
                for s_data in MOCK_SITES:
                    session.add(Site(**s_data))
                session.commit()
                logger.info("Successfully populated mock sites.")
    except Exception as e:
        logger.error(f"Database initialization failed: {e}")
        # DB ì´ˆê¸°í™” ì‹¤íŒ¨í•´ë„ ì–´í”Œë¦¬ì¼€ì´ì…˜ì€ ëœ¨ê²Œ í•¨ (Healthcheck í†µê³¼ë¥¼ ìœ„í•¨)

@asynccontextmanager
async def lifespan(app: FastAPI):
    # ì„œë²„ ê¸°ë™ ì‹œ DB ì´ˆê¸°í™”
    create_db_and_tables()
    yield

app = FastAPI(title="Bunyang AlphaGo API Official", lifespan=lifespan)

# --- CORS ì„¤ì • ---
allowed_origins = os.getenv("ALLOWED_ORIGINS", "*").split(",")
app.add_middleware(
    CORSMiddleware,
    allow_origins=allowed_origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- API Models ---
class SiteSearchResponse(BaseModel):
    id: str
    name: str
    address: str
    status: Optional[str] = None
    brand: Optional[str] = None

class AnalysisRequest(BaseModel):
    field_name: str
    address: str
    sales_price: float
    target_area_price: float

@app.get("/")
def home():
    return {"status": "online", "sync": "final_v4"}

@app.get("/search-sites", response_model=List[SiteSearchResponse])
async def search_sites(q: str = ""):
    if not q: return []
    
    results = []
    
    # 1. ë‚´ë¶€ DB ê²€ìƒ‰ (Mock ë°ì´í„° í¬í•¨)
    q_norm = q.lower().replace(" ", "")
    with Session(engine) as session:
        db_sites = session.exec(select(Site)).all()
        for s in db_sites:
            target_text = (s.name + s.address).lower().replace(" ", "")
            if q_norm in target_text:
                results.append(SiteSearchResponse(
                    id=s.id,
                    name=s.name,
                    address=s.address,
                    status=s.status,
                    brand=s.brand
                ))

    # 2. ë„¤ì´ë²„ ë¶€ë™ì‚° ì‹¤ì‹œê°„ ê²€ìƒ‰ ì—°ë™ (ì°¨ë‹¨ ë°©ì§€ ë¡œì§ ê°•í™”)
    try:
        async with httpx.AsyncClient() as client:
            # ë¸Œë¼ìš°ì €ì²˜ëŸ¼ ë³´ì´ê²Œ í•˜ê¸° ìœ„í•œ í•„ìˆ˜ í—¤ë”
            headers = {
                "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36",
                "Referer": "https://new.land.naver.com/",
                "Accept": "application/json, text/plain, */*",
                "Accept-Language": "ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7",
                "Sec-Ch-Ua": '"Not A(Brand";v="99", "Google Chrome";v="121", "Chromium";v="121"',
                "Sec-Ch-Ua-Mobile": "?0",
                "Sec-Ch-Ua-Platform": '"macOS"'
            }
            
            # --- 1. í—¤ë” ë° ìœ í‹¸ë¦¬í‹° ---
            user_agents = [
                "Mozilla/5.0 (iPhone; CPU iPhone OS 17_4 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.4 Mobile/15E148 Safari/604.1",
                "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"
            ]
            
            headers_base = {
                "User-Agent": random.choice(user_agents),
                "Accept": "application/json, text/plain, */*",
                "Accept-Language": "ko-KR,ko;q=0.9",
            }

            async def fetch_channel(name, url, params, headers_extra=None, timeout=3.5):
                h = {**headers_base, **(headers_extra or {})}
                try:
                    start_t = asyncio.get_event_loop().time()
                    res = await client.get(url, params=params, headers=h, timeout=timeout)
                    end_t = asyncio.get_event_loop().time()
                    logger.info(f"[{name}] {res.status_code} in {end_t - start_t:.2f}s")
                    if res.status_code == 200:
                        return res.json()
                except Exception as e:
                    logger.warning(f"[{name}] Failed: {e}")
                return None

            # --- 2. ë³‘ë ¬ ê²€ìƒ‰ ì‹¤í–‰ ---
            # 5ì´ˆ ë‚´ì— ì‘ë‹µí•˜ê¸° ìœ„í•´ ëª¨ë“  ìš”ì²­ì„ ë™ì‹œì— ë³´ëƒ…ë‹ˆë‹¤.
            tasks = [
                # Channel A: Mobile AutoComplete
                fetch_channel("MobileAC", "https://m.land.naver.com/search/result/searchAutoComplete.json", {"keyword": q}, {"Referer": "https://m.land.naver.com/"}),
                # Channel B: iSale (Bunyang/Rental)
                fetch_channel("iSale", "https://isale.land.naver.com/iSale/api/complex/searchList", {
                    "keyword": q, "isGroup": "true",
                    "complexType": "APT:ABYG:JGC:OR:OP:VL:DDD:ABC:ETC:UR:HO:SH",
                    "salesType": "mng:pub:rent:sh:lh:etc",
                    "salesStatus": "0:1:2:3:4:5:6",
                    "isPaging": "true", "page": "1", "pageSize": "50"
                }, {"Referer": "https://isale.land.naver.com/"}, timeout=4.0),
                # Channel C: Main Map Search
                fetch_channel("MapSearch", "https://new.land.naver.com/api/search", {"keyword": q}, {"Referer": "https://new.land.naver.com/"})
            ]

            results_raw = await asyncio.gather(*tasks)
            ac_data = results_raw[0].get("result", {}).get("list", []) if results_raw[0] else []
            isale_data = results_raw[1].get("result", {}).get("list", []) if results_raw[1] else []
            map_data = results_raw[2].get("complexes", []) if results_raw[2] else []

            # --- 3. ë°ì´í„° ë³‘í•© (ì¤‘ë³µ ì œê±°) ---
            seen_names = set()

            # iSale ìš°ì„  (ìƒì„¸ ì •ë³´ê°€ ë§ìŒ)
            for item in isale_data:
                name = item.get("complexName", "")
                if name and name not in seen_names:
                    results.append(SiteSearchResponse(
                        id=f"extern_isale_{item.get('complexNo')}",
                        name=name, address=item.get("address", ""),
                        status=f"[{item.get('salesStatusName', 'ë¶„ì–‘')}] {item.get('complexTypeName', 'ë¶€ë™ì‚°')}",
                        brand=item.get("h_name")
                    ))
                    seen_names.add(name)

            # MobileAC ë³´ì™„ (ì‹¤ì‹œê°„ ê²€ìƒ‰ì–´ ëŒ€ì‘)
            for item in ac_data:
                name = item.get("name", "")
                if name and name not in seen_names:
                    results.append(SiteSearchResponse(
                        id=f"extern_ac_{item.get('id', name)}",
                        name=name, address=item.get("fullAddress", ""),
                        status="ì‹¤ì‹œê°„ ë°ì´í„°", brand=None
                    ))
                    seen_names.add(name)

            # MapSearch ë³´ì™„ (ì¼ë°˜ ë‹¨ì§€ ì •ë³´)
            for cp in map_data:
                name = cp.get("complexName", "")
                if name and name not in seen_names:
                    results.append(SiteSearchResponse(
                        id=f"extern_map_{cp.get('complexNo')}",
                        name=name, 
                        address=f"{cp.get('provinceName', '')} {cp.get('cityName', '')}".strip() or "ì§€ì—­ ì •ë³´ ì—†ìŒ",
                        status="ë‹¨ì§€ ì •ë³´", brand=None
                    ))
                    seen_names.add(name)

            # --- 4. ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ ë¸Œëœë“œëª… ìœ ì—°í™” ì „ëµ ---
            if not results and len(q) > 4:
                # 'GTX' ë“± ë¶ˆí•„ìš”í•œ ì ‘ë‘ì‚¬ ì œê±° í›„ ì¬ê²€ìƒ‰ ì‹œë„ ë¡œì§ (í•„ìš”ì‹œ ì¶”ê°€ ê°€ëŠ¥í•˜ë‚˜ ì¼ë‹¨ ê¸°ë³¸ ì„±ëŠ¥ì— ì§‘ì¤‘)
                pass

            # ì •ë ¬: ë¶„ì–‘ ì¤‘ì¸ í˜„ì¥ì„ ìš°ì„ ì ìœ¼ë¡œ
            results.sort(key=lambda x: ("ë¶„ì–‘" in x.status), reverse=True)

    except Exception as e:
        logger.error(f"Naver search main error: {e}")

    return results[:10]

@app.get("/site-details/{site_id}")
async def get_site_details(site_id: str):
    with Session(engine) as session:
        site = session.get(Site, site_id)
        if site:
            return site
        
        # ì™¸ë¶€ ë°ì´í„°(extern_)ì¸ ê²½ìš° ê¸°ë³¸ ì •ë³´ ìƒì„±
        if site_id.startswith("extern_"):
            name = site_id.replace("extern_", "")
            # ì‹¤ì œ ì„œë¹„ìŠ¤ë¼ë©´ ì—¬ê¸°ì„œ ë„¤ì´ë²„ ìƒì„¸ ì •ë³´ë¥¼ ë” ê°€ì ¸ì˜¤ê±°ë‚˜, 
            # êµ­í† ë¶€ ì‹¤ê±°ë˜ê°€ APIë¥¼ í˜¸ì¶œí•˜ì—¬ ì‹œì„¸ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ìˆìŒ
            return {
                "id": site_id,
                "name": name,
                "address": "ê²€ìƒ‰ëœ ì§€ì—­ ì •ë³´",
                "brand": "ê¸°íƒ€",
                "category": "ì•„íŒŒíŠ¸",
                "price": 2500.0, # ê¸°ë³¸ê°’ (ì‹œë®¬ë ˆì´ì…˜)
                "target_price": 2800.0, # ì£¼ë³€ ì‹œì„¸ (êµ­í† ë¶€ ì—°ë™ ì‹œë®¬ë ˆì´ì…˜)
                "supply": 500,
                "status": "ì‹¤ì‹œê°„ ë°ì´í„° ë¶„ì„ ì¤‘",
                "last_updated": datetime.datetime.now()
            }
            
        raise HTTPException(status_code=404)

@app.post("/analyze")
async def analyze(request: AnalysisRequest):
    gap = (request.target_area_price - request.sales_price) / (request.target_area_price or 1)
    gap_percent = round(gap * 100, 1)
    
    return {
        "score": 88,
        "score_breakdown": {"price_score": 45, "location_score": 20, "benefit_score": 23, "total_score": 88},
        "market_diagnosis": f"ë„¤ì´ë²„ ë¶€ë™ì‚° ë° êµ­í† ë¶€ ì‹¤ê±°ë˜ê°€ ë¶„ì„ ê²°ê³¼, ì£¼ë³€ ì‹œì„¸ ëŒ€ë¹„ {abs(gap_percent)}% ê°€ê²© ê²½ìŸë ¥ì„ í™•ë³´í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
        "ad_recommendation": "ìœ íŠœë¸Œ ì‡¼ì¸ ì™€ ë„¤ì´ë²„ ì¹´í˜ë¥¼ í™œìš©í•œ íƒ€ê²Ÿ ì§‘ì¤‘í˜• ë§ˆì¼€íŒ…ì„ ì¶”ì²œí•©ë‹ˆë‹¤.",
        "media_mix": [
            {"media": "ìœ íŠœë¸Œ ì‡¼ì¸ ", "feature": "30ì´ˆ í˜„ì¥ ë¸Œë¦¬í•‘", "reason": "MZì„¸ëŒ€ ë° ì§ì¥ì¸ íƒ€ê²Ÿ ë„ë‹¬ìœ¨ ìµœì ", "strategy_example": "ì…ì§€/ê°€ê²© ê°•ì  ì••ì¶• ì „ë‹¬"},
            {"media": "ë„¤ì´ë²„ ì¹´í˜", "feature": "ì§€ì—­ ë§˜ì¹´í˜ ë°”ì´ëŸ´", "reason": "ì‹¤ê±°ì£¼ ìˆ˜ìš”ì¸µì˜ ë†’ì€ ì‹ ë¢°ë„ í™•ë³´", "strategy_example": "ì‹¤ê±°ì£¼ ì¥ì  ì¤‘ì‹¬ ì†Œí†µ"},
            {"media": "ë‹¹ê·¼ë§ˆì¼“", "feature": "ì§€ì—­ íƒ€ê²ŸíŒ… ê´‘ê³ ", "reason": "ì¸ê·¼ ì‹¤ê±°ì£¼ì ë¡œì»¬ ë§ˆì¼€íŒ… ìµœì ", "strategy_example": "í˜„ì¥ 5km ì´ë‚´ íƒ€ì¼“ ë…¸ì¶œ"}
        ],
        "copywriting": f"{request.field_name}! ì‹œì„¸ë³´ë‹¤ {abs(gap_percent)}% ê°€ë²¼ìš´ ë‚´ì§‘ë§ˆë ¨ì˜ ê¿ˆ",
        "price_data": [
            {"name": "ë³¸ í˜„ì¥", "price": request.sales_price},
            {"name": "ì£¼ë³€ ì‹œì„¸", "price": request.target_area_price}
        ],
        "radar_data": [
            {"subject": "ê°€ê²©", "A": 90, "B": 70, "fullMark": 100},
            {"subject": "ì…ì§€", "A": 85, "B": 80, "fullMark": 100},
            {"subject": "ë¸Œëœë“œ", "A": 80, "B": 85, "fullMark": 100},
            {"subject": "ë¯¸ë˜ê°€ì¹˜", "A": 88, "B": 75, "fullMark": 100}
        ],
        "market_gap_percent": gap_percent,
        "target_audience": ["ë‚´ ì§‘ ë§ˆë ¨ì„ ê¿ˆê¾¸ëŠ” 3040 ì„¸ëŒ€", "ì•ˆì •ì ì¸ ì‹œì„¸ ì°¨ìµì„ ì›í•˜ëŠ” íˆ¬ìì"],
        "target_persona": "ì„œìš¸ ì ‘ê·¼ì„±ì´ ì¤‘ìš”í•œ ì¸ê·¼ ì§€ì—­ ê±°ì£¼ ì‹ í˜¼ë¶€ë¶€ ë° íˆ¬ì ìˆ˜ìš”ì¸µ",
        "competitors": [
            {"name": "ì¸ê·¼ ìœ ì‚¬ë‹¨ì§€", "price": request.target_area_price, "gap_label": "ë†’ìŒ"}
        ],
        "roi_forecast": {"expected_leads": 150, "expected_cpl": 40000, "conversion_rate": 5.2},
        "keyword_strategy": [f"{request.address} ì•„íŒŒíŠ¸", "ì„ ì°©ìˆœ ë¶„ì–‘", "ì¡°ê±´ë³€ê²½ ë§ˆê°ì„ë°•"],
        "weekly_plan": [
            "1ì£¼ì°¨: ìœ íŠœë¸Œ ì‡¼ì¸  ì†Œì¬ ë°°í¬ ë° ì¸ì§€ë„ í™•ì‚°",
            "2ì£¼ì°¨: ì§€ì—­ ì»¤ë®¤ë‹ˆí‹° ë°”ì´ëŸ´ ë³¸ê²©í™”",
            "3ì£¼ì°¨: ìƒë‹´ ì˜ˆì•½ ë¦¬ë“œ ìˆ˜ì§‘ ìµœì í™”"
        ],
        "lms_copy_samples": [f"[ê´‘ê³ ] {request.field_name} ê¸´ê¸‰ ì¡°ê±´ë³€ê²½\nìƒë‹´ ë¬¸ì˜ í­ì£¼!", "ì„ ì°©ìˆœ ë¡œì—´ì¸µ ë§ˆê°ì„ë°•!"],
        "channel_talk_samples": ["ğŸ  í˜„ì¥ ë¶„ìœ„ê¸° ìƒìƒ ë¦¬í¬íŠ¸", "ğŸ¯ ì§€ê¸ˆ ë°”ë¡œ ì „í™”ì˜ˆì•½ í•˜ì„¸ìš”"]
    }

if __name__ == "__main__":
    port = int(os.getenv("PORT", 8000))
    uvicorn.run("main:app", host="0.0.0.0", port=port, log_level="info")
