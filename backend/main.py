from fastapi import FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Optional
import random
import datetime
import os
import uvicorn
import asyncio
from contextlib import asynccontextmanager
from sqlmodel import Field, Session, SQLModel, create_engine, select, or_, col
import logging
import httpx
import google.generativeai as genai
import json

# Gemini API ì„¤ì •
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "AIzaSyBlZMZOEpfCkXiRWjfUADR_nVmyZdsTBRE")
genai.configure(api_key=GEMINI_API_KEY)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# --- Database Setup ---
sqlite_file_name = "database.db"
sqlite_url = f"sqlite:///{sqlite_file_name}"
engine = create_engine(sqlite_url, connect_args={"check_same_thread": False})

class Site(SQLModel, table=True):
    __table_args__ = {'extend_existing': True}
    
    id: str = Field(primary_key=True)
    name: str
    address: str
    brand: Optional[str] = None
    category: str
    price: float
    target_price: float
    supply: int
    status: Optional[str] = None
    last_updated: datetime.datetime = Field(default_factory=datetime.datetime.now)

# --- NATIONWIDE START DATA ---
MOCK_SITES = [
    {"id": "h_uj1", "name": "í•´ë§í„´ í”Œë ˆì´ìŠ¤ ì˜ì •ë¶€ì—­", "address": "ê²½ê¸°ë„ ì˜ì •ë¶€ì‹œ", "brand": "í•´ë§í„´", "category": "ì•„íŒŒíŠ¸", "price": 2300, "target_price": 2600, "supply": 612, "status": "ê³µê³ ì¢…ë£Œ"},
    {"id": "dj_doan1", "name": "íìŠ¤í…Œì´íŠ¸ ë„ì•ˆë¦¬ë²„íŒŒí¬ 1ë‹¨ì§€", "address": "ëŒ€ì „ê´‘ì—­ì‹œ ìœ ì„±êµ¬", "brand": "íìŠ¤í…Œì´íŠ¸", "category": "ì•„íŒŒíŠ¸", "price": 1950, "target_price": 2200, "supply": 1124, "status": "ë¶„ì–‘ì¤‘"},
    {"id": "jt1", "name": "ì˜ì •ë¶€ì—­ ìŠ¤ë§ˆíŠ¸ì‹œí‹°(ì§€ì—­ì£¼íƒì¡°í•©)", "address": "ê²½ê¸°ë„ ì˜ì •ë¶€ì‹œ", "brand": "ê¸°íƒ€", "category": "ì§€ì—­ì£¼íƒì¡°í•©", "price": 1500, "target_price": 1750, "supply": 1614, "status": "ì¡°í•©ì›ëª¨ì§‘"},
    {"id": "uj_topseok1", "name": "ì˜ì •ë¶€ íƒ‘ì„ ì„¼íŠ¸ëŸ´íŒŒí¬ í‘¸ë¥´ì§€ì˜¤", "address": "ê²½ê¸°ë„ ì˜ì •ë¶€ì‹œ íƒ‘ì„ë™", "brand": "í‘¸ë¥´ì§€ì˜¤", "category": "ì•„íŒŒíŠ¸", "price": 2400, "target_price": 2700, "supply": 840, "status": "ë¶„ì–‘ì˜ˆì •"},
    {"id": "uj_hoeryong1", "name": "ì˜ì •ë¶€ íšŒë£¡ íŒŒí¬ë·° ìì´", "address": "ê²½ê¸°ë„ ì˜ì •ë¶€ì‹œ íšŒë£¡ë™", "brand": "ìì´", "category": "ì•„íŒŒíŠ¸", "price": 2200, "target_price": 2500, "supply": 650, "status": "ë¶„ì–‘ì¤‘"},
    {"id": "uj_hoeryong2", "name": "íšŒë£¡ì—­ ë¡¯ë°ìºìŠ¬", "address": "ê²½ê¸°ë„ ì˜ì •ë¶€ì‹œ íšŒë£¡ë™", "brand": "ë¡¯ë°ìºìŠ¬", "category": "ì•„íŒŒíŠ¸", "price": 2350, "target_price": 2650, "supply": 720, "status": "ë¶„ì–‘ì˜ˆì •"},
    {"id": "uj_topseok2", "name": "íƒ‘ì„ì—­ íìŠ¤í…Œì´íŠ¸", "address": "ê²½ê¸°ë„ ì˜ì •ë¶€ì‹œ íƒ‘ì„ë™", "brand": "íìŠ¤í…Œì´íŠ¸", "category": "ì•„íŒŒíŠ¸", "price": 2450, "target_price": 2750, "supply": 890, "status": "ë¶„ì–‘ì¤‘"},
]

def create_db_and_tables():
    SQLModel.metadata.create_all(engine)
    with Session(engine) as session:
        for s_data in MOCK_SITES:
            existing = session.get(Site, s_data["id"])
            if not existing:
                session.add(Site(**s_data))
            else:
                for key, value in s_data.items():
                    setattr(existing, key, value)
        session.commit()

@asynccontextmanager
async def lifespan(app: FastAPI):
    create_db_and_tables()
    # ì„œë²„ ì‹œì‘ ì‹œ CSV ë°ì´í„° ìë™ ë¡œë“œ (ë°ì´í„° ìœ ì‹¤ ë°©ì§€)
    try:
        import csv
        csv_file = "sites_data.csv"
        if os.path.exists(csv_file):
            with Session(engine) as session:
                with open(csv_file, 'r', encoding='utf-8') as f:
                    reader = csv.DictReader(f)
                    for row in reader:
                        site_id = row['id']
                        if not session.get(Site, site_id):
                            session.add(Site(
                                id=site_id,
                                name=row['name'],
                                address=row['address'],
                                brand=row['brand'] if row['brand'] else None,
                                category=row['category'],
                                price=float(row['price']),
                                target_price=float(row['target_price']),
                                supply=int(row['supply']),
                                status=row['status'] if row['status'] else None
                            ))
                    session.commit()
            logger.info("CSV data auto-imported on startup.")
    except Exception as e:
        logger.error(f"Startup data import error: {e}")
    yield

app = FastAPI(lifespan=lifespan)

# CORS ì„¤ì •ì„ ë” ëª…ì‹œì ìœ¼ë¡œ ê°•í™”
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["GET", "POST", "OPTIONS"],
    allow_headers=["*"],
    expose_headers=["*"],
)

class SiteSearchResponse(BaseModel):
    id: str
    name: str
    address: str
    status: Optional[str] = None
    brand: Optional[str] = None
    category: Optional[str] = None

@app.get("/search-sites", response_model=List[SiteSearchResponse])
async def search_sites(q: str):
    if not q or len(q) < 2:
        return []

    results = []
    seen_ids = set()
    q_lower = q.lower().strip()

    # 1. DB ê²€ìƒ‰ (ë¶„ì–‘ ë°ì´í„°ë² ì´ìŠ¤ ìš°ì„ )
    try:
        with Session(engine) as session:
            # ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´ ê²€ìƒ‰ (name, address, brand, category, status ëª¨ë‘ ê²€ìƒ‰)
            statement = select(Site).where(
                or_(
                    col(Site.name).ilike(f"%{q}%"), 
                    col(Site.address).ilike(f"%{q}%"), 
                    col(Site.brand).ilike(f"%{q}%"),
                    col(Site.category).ilike(f"%{q}%"),
                    col(Site.status).ilike(f"%{q}%")
                )
            ).order_by(col(Site.last_updated).desc()).limit(100)
            db_sites = session.exec(statement).all()
            for s in db_sites:
                if s.id not in seen_ids:
                    results.append(SiteSearchResponse(id=s.id, name=s.name, address=s.address, status=s.status, brand=s.brand, category=s.category))
                    seen_ids.add(s.id)
    except Exception as e:
        logger.error(f"DB search error: {e}")

    # 2. ì‹¤ì‹œê°„ ë¶„ì–‘ ì „ë¬¸ API ê²€ìƒ‰ (êµ¬ì¶• ì•„íŒŒíŠ¸ë¥¼ ì›ì²œ ë°°ì œí•˜ê¸° ìœ„í•´ isale APIë§Œ ì‚¬ìš©)
    try:
        async with httpx.AsyncClient(follow_redirects=True) as client:
            fake_nnb = "".join(random.choices("0123456789ABCDEF", k=16))
            h = {
                "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
                "Accept": "application/json, text/plain, */*",
                "Accept-Language": "ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7",
                "Accept-Encoding": "gzip, deflate, br",
                "Referer": "https://m.land.naver.com/",
                "Origin": "https://m.land.naver.com",
                "Cookie": f"NNB={fake_nnb}",
                "Sec-Fetch-Dest": "empty",
                "Sec-Fetch-Mode": "cors",
                "Sec-Fetch-Site": "same-site"
            }
            
            # ë¶„ì–‘ ì •ë³´ê°€ ìˆëŠ” 'isale' ë°ì´í„°ë² ì´ìŠ¤ë§Œ ì¡°íšŒ (ì˜¤ë˜ëœ ê¸°ì¶• ì•„íŒŒíŠ¸ëŠ” ì—¬ê¸°ì„œ ê±¸ëŸ¬ì§)
            url_isale = "https://isale.land.naver.com/iSale/api/complex/searchList"
            params = {
                "keyword": q, 
                "complexType": "APT:ABYG:JGC:OR:OP:VL:DDD:ABC:ETC:UR:HO:SH", 
                "salesStatus": "0:1:2:3:4:5:6:7:8:9:10:11:12", 
                "pageSize": "100"
            }
            res_isale = await client.get(url_isale, params=params, headers=h, timeout=3.0)
            if res_isale.status_code == 200:
                data = res_isale.json()
                for it in data.get("result", {}).get("list", []):
                    sid = f"extern_isale_{it.get('complexNo')}"
                    if sid not in seen_ids:
                        results.append(SiteSearchResponse(
                            id=sid, name=it.get('complexName'), address=it.get('address'), 
                            status=it.get('salesStatusName'), brand=it.get('h_name'),
                            category=it.get('complexTypeName', 'ì•„íŒŒíŠ¸')
                        ))
                        seen_ids.add(sid)
    except Exception as e:
        logger.error(f"API search error: {e}")

    # ê²€ìƒ‰ ê²°ê³¼ ì •ë ¬ - í˜„ì¥ëª…ì— ê²€ìƒ‰ì–´ê°€ í¬í•¨ëœ ê²½ìš° ìš°ì„  í‘œì‹œ
    def sort_key(x):
        name_lower = x.name.lower() if x.name else ""
        address_lower = x.address.lower() if x.address else ""
        
        # ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ê²½ìš° ìµœìš°ì„ 
        if name_lower == q_lower:
            return (0, 0)
        # í˜„ì¥ëª…ì´ ê²€ìƒ‰ì–´ë¡œ ì‹œì‘í•˜ëŠ” ê²½ìš°
        if name_lower.startswith(q_lower):
            return (1, name_lower.find(q_lower))
        # í˜„ì¥ëª…ì— ê²€ìƒ‰ì–´ê°€ í¬í•¨ëœ ê²½ìš°
        if q_lower in name_lower:
            return (2, name_lower.find(q_lower))
        # ì£¼ì†Œì— ê²€ìƒ‰ì–´ê°€ í¬í•¨ëœ ê²½ìš°
        if q_lower in address_lower:
            return (3, address_lower.find(q_lower))
        # ê·¸ ì™¸
        return (999, 999)
    
    results.sort(key=sort_key)
    logger.info(f"Search query: '{q}' returned {len(results)} results")
    return results[:100]

@app.get("/sync-all")
async def sync_all():
    # êµ¬ì¶•ì„ ì œì™¸í•œ ì „êµ­ì˜ 'ìµœê·¼ 5ë…„ ë‚´' ë¶„ì–‘/ì„ëŒ€/ì§€ì£¼íƒ ë¦¬ìŠ¤íŠ¸ í€€í…€ ë™ê¸°í™”
    keywords = [
        "í•´ë§í„´", "ì¨ë°‹", "ë””ì—íŠ¸ë¥´", "ì§€ì—­ì£¼íƒì¡°í•©", "ì§€ì£¼íƒ", "ë¯¸ë¶„ì–‘", "ì„ ì°©ìˆœ",
        "ëŒ€ì „", "ì˜ì •ë¶€", "ë¶€ì‚°", "ì„œìš¸", "ì¸ì²œ", "ê²½ê¸°", "ìˆ˜ì›", "ì„±ë‚¨",
        "íƒ‘ì„", "íšŒë£¡", "íŒŒí¬ë·°", "íìŠ¤í…Œì´íŠ¸", "ìì´", "í‘¸ë¥´ì§€ì˜¤", "eí¸í•œì„¸ìƒ",
        "ë¡¯ë°ìºìŠ¬", "ì•„ì´íŒŒí¬", "ë”ìƒµ", "ì„¼íŠ¸ëŸ´", "í¬ë ˆìŠ¤íŠ¸", "ë ˆì´í¬", "ìŠ¤ì¹´ì´"
    ]
    count = 0
    async with httpx.AsyncClient() as client:
        for kw in keywords:
            try:
                fake_nnb = "".join(random.choices("0123456789ABCDEF", k=16))
                h = {"User-Agent": "Mozilla/5.0", "Cookie": f"NNB={fake_nnb}"}
                url = "https://isale.land.naver.com/iSale/api/complex/searchList"
                params = {"keyword": kw, "complexType": "APT:ABYG:JGC:OR:OP:VL:DDD:ABC:ETC:UR:HO:SH", "salesStatus": "0:1:2:3:4:5:6:7:8:9:10:11:12", "pageSize": "100"}
                res = await client.get(url, params=params, headers=h, timeout=8.0)
                if res.status_code == 200:
                    items = res.json().get("result", {}).get("list", [])
                    with Session(engine) as session:
                        for it in items:
                            sid = f"extern_isale_{it.get('complexNo')}"
                            if not session.get(Site, sid):
                                session.add(Site(
                                    id=sid, name=it.get("complexName"), address=it.get("address"),
                                    brand=it.get("h_name"), category=it.get("complexTypeName", "ë¶€ë™ì‚°"),
                                    price=1900.0, target_price=2200.0, supply=500, status=it.get("salesStatusName")
                                ))
                                count += 1
                        session.commit()
                await asyncio.sleep(0.3)
            except: pass
    return {"status": "sync_completed", "new_items": count, "message": "ë¶„ì–‘/ì„ëŒ€/ì§€ì£¼íƒ ì „ë¬¸ ë°ì´í„° ë™ê¸°í™”ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. (êµ¬ì¶• ì œì™¸)"}

@app.get("/site-details/{site_id}")
async def get_site_details(site_id: str):
    with Session(engine) as session:
        site = session.get(Site, site_id)
        if site: return site
        return {"id": site_id, "name": "ë¶„ì–‘ ë¶„ì„ ì™„ë£Œ", "address": "ì§€ì—­ ì •ë³´", "brand": "ê¸°íƒ€", "category": "ë¶€ë™ì‚°", "price": 2500, "target_price": 2800, "supply": 500, "status": "ë°ì´í„° ë¡œë“œ"}

class AnalyzeRequest(BaseModel):
    field_name: Optional[str] = "ì•Œ ìˆ˜ ì—†ëŠ” í˜„ì¥"
    address: Optional[str] = "ì§€ì—­ ì •ë³´ ì—†ìŒ"
    product_category: Optional[str] = "ì•„íŒŒíŠ¸"
    sales_stage: Optional[str] = "ë¶„ì–‘ì¤‘"
    down_payment: Optional[int] = 10
    interest_benefit: Optional[str] = "ì—†ìŒ"
    additional_benefits: Optional[str] = "ì—†ìŒ"
    main_concern: Optional[str] = "ê¸°íƒ€"
    monthly_budget: Optional[int] = 0
    existing_media: Optional[str] = "ì—†ìŒ"
    sales_price: Optional[float] = 0.0
    target_area_price: Optional[float] = 0.0
    down_payment_amount: Optional[int] = 0
    supply_volume: Optional[int] = 0
    field_keypoints: Optional[str] = ""
    user_email: Optional[str] = None

@app.post("/analyze")
async def analyze_site(request: Optional[AnalyzeRequest] = None):
    """Gemini AIë¥¼ ì‚¬ìš©í•œ í˜„ì¥ ì •ë°€ ë¶„ì„ API (ê³ ë„í™” ë²„ì „)"""
    try:
        req = request if request else AnalyzeRequest()
        
        # ì •ë³´ ì¶”ì¶œ
        field_name = getattr(req, 'field_name', "ë¶„ì„ í˜„ì¥")
        address = getattr(req, 'address', "ì§€ì—­ ì •ë³´ ì—†ìŒ")
        product_category = getattr(req, 'product_category', "ì•„íŒŒíŠ¸")
        sales_price = float(getattr(req, 'sales_price', 0.0) or 0.0)
        target_price = float(getattr(req, 'target_area_price', 0.0) or 0.0)
        supply_volume = int(getattr(req, 'supply_volume', 0) or 0)
        main_concern = getattr(req, 'main_concern', "ê¸°íƒ€")
        field_keypoints = getattr(req, 'field_keypoints', "")
        
        # 1. ì‹¤ì‹œê°„ ì—¬ë¡  ë° ë°ì´í„° ìˆ˜ì§‘ (ë„¤ì´ë²„ ë‰´ìŠ¤/ë¸”ë¡œê·¸ ê²€ìƒ‰)
        search_context = ""
        try:
            async with httpx.AsyncClient() as client:
                # í˜„ì¥ëª…ìœ¼ë¡œ ìµœì‹  ì •ë³´ ê²€ìƒ‰
                search_url = "https://search.naver.com/search.naver"
                search_params = {"query": f"{field_name} ë¶„ì–‘ê°€ ëª¨ë¸í•˜ìš°ìŠ¤", "where": "view"}
                h = {"User-Agent": "Mozilla/5.0"}
                res = await client.get(search_url, params=search_params, headers=h, timeout=4.0)
                if res.status_code == 200:
                    search_context = res.text[:3000]
        except Exception as e:
            logger.warning(f"Live search skipped due to error: {e}")

        # 2. AI ë¶„ì„ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ì‘ì„±
        prompt = f"""
        ë‹¹ì‹ ì€ ìƒìœ„ 1% ë¶€ë™ì‚° ë§ˆì¼€íŒ… ì „ë¬¸ê°€ì…ë‹ˆë‹¤. [{field_name}] í˜„ì¥ì˜ í•„ìŠ¹ ì „ëµì„ JSONìœ¼ë¡œ ì‘ì„±í•˜ì‹­ì‹œì˜¤.
        
        [í˜„ì¥ ì •ë³´]
        í˜„ì¥: {field_name} / ìœ„ì¹˜: {address} / ìƒí’ˆ: {product_category}
        ê°€ê²©: ìš°ë¦¬ {sales_price} VS ì£¼ë³€ {target_price}
        íŠ¹ì§•: {field_keypoints} / ê³ ë¯¼: {main_concern}
        
        [ê²€ìƒ‰ì°¸ê³ ] {search_context[:1000] if search_context else "ê²€ìƒ‰ ë°ì´í„° ì—†ìŒ"}
        
        [ì¶œë ¥ ê·œê²©]
        ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ì„ ìœ ì§€í•˜ë˜, ë‚´ìš©ì€ ì‹¤ì œ ì „ë¬¸ê°€ì²˜ëŸ¼ ì•„ì£¼ ìƒì„¸í•˜ê²Œ ì‘ì„±í•˜ì‹­ì‹œì˜¤. 
        ì ˆëŒ€ "ì‹œì¥ ê²½ìŸë ¥ì´ ì¶©ë¶„í•˜ë‹¤"ëŠ” ì‹ì˜ ì§§ì€ ë‹µë³€ì€ ê¸ˆì§€í•©ë‹ˆë‹¤.
        
        {{
            "market_diagnosis": "ìµœì†Œ 3ë¬¸ì¥ ì´ìƒì˜ ì‹¬ì¸µ ì‹œì¥ ë¶„ì„",
            "target_persona": "êµ¬ì²´ì ì¸ íƒ€ì¼“ ê³ ê° ìƒí™œìƒ ì •ì˜",
            "target_audience": ["#íƒœê·¸1", "#íƒœê·¸2", "#íƒœê·¸3", "#íƒœê·¸4", "#íƒœê·¸5"],
            "competitors": [
                {{"name": "ê²½ìŸë‹¨ì§€A", "price": {target_price}, "distance": "1.0km"}},
                {{"name": "ê²½ìŸë‹¨ì§€B", "price": {target_price * 1.1 if target_price > 0 else sales_price * 1.1:.0f}, "distance": "2.5km"}}
            ],
            "ad_recommendation": "êµ¬ì²´ì ì¸ ë§¤ì²´ ì§‘í–‰ ë¹„ì¤‘ê³¼ ì´ìœ ",
            "copywriting": "í›„í‚¹ ë„˜ì¹˜ëŠ” ë©”ì¸ ì¹´í”¼",
            "keyword_strategy": ["í‚¤ì›Œë“œ1", "2", "3", "4", "5"],
            "weekly_plan": ["1ì£¼ ì•¡ì…˜", "2ì£¼ ì•¡ì…˜", "3ì£¼ ì•¡ì…˜", "4ì£¼ ì•¡ì…˜"],
            "roi_forecast": {{"expected_leads": 130, "expected_cpl": 45000, "conversion_rate": 3.5}},
            "lms_copy_samples": [
                "(ê´‘ê³ ) [ì‹ ë¢°/ì¢…í•©] {{field_name}} - ì™„ë²½í•œ ì£¼ê±°ì™€ ë¯¸ë˜ ê°€ì¹˜ì˜ ì¤‘ì‹¬\\n\\nì•ˆë…•í•˜ì„¸ìš”, {{field_name}} ë¶„ì–‘ë³¸ë¶€ì…ë‹ˆë‹¤.\\nì…ì§€ë¶€í„° ê°€ê²©ê¹Œì§€, ì§€ì—­ì˜ ìƒˆë¡œìš´ ê¸°ì¤€ì´ ë  í˜„ì¥ì„ ì†Œê°œí•©ë‹ˆë‹¤.\\n\\nğŸ¡ í˜„ì¥ í•µì‹¬ í¬ì¸íŠ¸:\\n- {{field_keypoints}}\\n- ì£¼ë³€ ì‹œì„¸ ëŒ€ë¹„ {gap_percent}% ë” í•©ë¦¬ì ì¸ ë¶„ì–‘ê°€\\n- ì‹ ì¶• í”„ë¦¬ë¯¸ì—„ê³¼ ì••ë„ì  ìƒí™œê¶Œ ê³µìœ \\n\\nğŸ í•œì • ê¸°ê°„ íŠ¹ë³„ í˜œíƒ:\\n- ê³„ì•½ê¸ˆ {{down_payment}} ì •ì•¡ì œë¡œ ì…ì£¼ ì‹œê¹Œì§€ ë¶€ë‹´ ì œë¡œ\\n- ì¤‘ë„ê¸ˆ {{interest_benefit}} íŒŒê²© ì¡°ê±´ ì ìš©\\n- ì„ ì°©ìˆœ í’€ì˜µì…˜ ë¬´ìƒ ì œê³µ í˜œíƒê¹Œì§€\\n\\nì§€ê¸ˆ ë°”ë¡œ ìƒë‹´ ì‹ ì²­í•˜ì‹œê³  ì‹œì„¸ ì°¨ìµ í”„ë¦¬ë¯¸ì—„ì„ ì„ ì í•˜ì‹­ì‹œì˜¤.\\n\\nğŸ“ ë¶„ì–‘ í™ë³´ê´€: 1600-0000\\nâ–¶ ì‹¤ì‹œê°„ ì”ì—¬ì„¸ëŒ€ í™•ì¸: [ìƒë‹´ì˜ˆì•½ì‹ ì²­]",
                "(ê´‘ê³ ) [í˜œíƒì§‘ì¤‘] {{field_name}} - ë§ˆì§€ë§‰ ì„ ì°©ìˆœ ì¡°ê±´ë³€ê²½ ì•ˆë‚´\\n\\në§ˆí¬ê°€ ê¸°ë‹¤ë ¤ì˜¨ ë‹¨ í•˜ë‚˜ì˜ ê¸°íšŒ, {{field_name}}ì…ë‹ˆë‹¤.\\nê³ ë¯¼í•˜ì‹œëŠ” ì‚¬ì´ ë¡œì—´ì¸µë¶€í„° ë¹ ë¥´ê²Œ ì†Œì§„ë˜ê³  ìˆìŠµë‹ˆë‹¤.\\n\\nğŸ’° ê°•ë ¥í•œ ê¸ˆìœµ ì†”ë£¨ì…˜:\\n1. ì´ˆê¸° ìê¸ˆ ë¶€ë‹´ì„ ì¤„ì¸ ê³„ì•½ê¸ˆ {{down_payment}}\\n2. ê¸ˆë¦¬ ê±±ì • ì—†ëŠ” {{interest_benefit}} í˜œíƒ í™•ì •\\n3. ì£¼ë³€ ì‹œì„¸ì™€ ë¹„êµí• ìˆ˜ë¡ ì»¤ì§€ëŠ” {gap_percent}%ì˜ ìì‚° ê°€ì¹˜\\n\\në‹¨ìˆœí•œ ì§‘ì„ ë„˜ì–´, ì‚¶ì˜ í’ˆê²©ì´ ë°”ë€ŒëŠ” {{field_name}}ì—ì„œ ë‹¹ì‹ ì˜ ë¯¸ë˜ë¥¼ ì„¤ê³„í•˜ì‹­ì‹œì˜¤.\\n\\nğŸ“ í™ë³´ê´€ ìœ„ì¹˜ ì•ˆë‚´ ë° ìƒë‹´\\nâ–¶ 010-0000-0000 (24ì‹œê°„ ë¬¸ì ê°€ëŠ¥)",
                "(ê´‘ê³ ) [ë§ˆê°ì„ë°•] ğŸš¨ {{field_name}} ë¡œì—´ì¸µ ì„ ì°©ìˆœ ë§ˆê° 5ë¶„ ì „!\\n\\nì§€ê¸ˆ ì´ ë¬¸ìë¥¼ ë°›ìœ¼ì…¨ë‹¤ë©´ ì•„ì§ ê¸°íšŒê°€ ë‚¨ì•„ ìˆìŠµë‹ˆë‹¤.\\n{{field_name}} ì”ì—¬ ì„¸ëŒ€ê°€ ì‹¤ì‹œê°„ìœ¼ë¡œ ê³„ì•½ë˜ê³  ìˆìŠµë‹ˆë‹¤.\\n\\nğŸ”¥ í˜„ì¬ ìƒí™©:\\n- 84íƒ€ì… ë‚¨ì€ ìˆ˜ëŸ‰ ë‹¨ 3ì„¸ëŒ€!\\n- ë¡œì—´ì¸µ/ì •ë‚¨í–¥ í”„ë¦¬ë¯¸ì—„ ë¼ì¸ ë§ˆê° ì§ì „\\n- ì‹œì„¸ ì°¨ìµë§Œ {gap_percent}%ê°€ ì˜ˆìƒë˜ëŠ” ì••ë„ì  ìˆ˜ìµì„±\\n\\në” ì´ìƒ ë§ì„¤ì´ì§€ ë§ˆì„¸ìš”. ë‚´ ì§‘ ë§ˆë ¨ì˜ ê¿ˆ, ì „ë¬¸ê°€ì™€ ìƒì˜í•˜ì—¬ ì§€ê¸ˆ ê²°ì •í•˜ì‹­ì‹œì˜¤.\\n\\nğŸ“ ê¸´ê¸‰ ìƒë‹´ ë¬¸ì˜: 1600-1234\\n*ë°©ë¬¸ ì˜ˆì•½ ì‹œ íŠ¹ë³„ ì‚¬ì€í’ˆ ì¦ì • ì¤‘*"
            ],
            "channel_talk_samples": [
                "ğŸ”¥ [{{field_name}}] íŒŒê²© ì¡°ê±´ë³€ê²½ í™•ì •! ì„ ì°©ìˆœ 10ì„¸ëŒ€ í•œì • íŠ¹ë³„ í˜œíƒì„ ì§€ê¸ˆ í™•ì¸í•˜ì„¸ìš”.",
                "ğŸš¨ [{{field_name}}] ì‹¤ì‹œê°„ ì”ì—¬ì„¸ëŒ€ ê¸‰ì†Œì§„! ë¡œì—´ì¸µ ë‚¨ì€ ìˆ˜ëŸ‰ 3ê°œ, ì§€ê¸ˆ ë°”ë¡œ ì„ ì í•˜ì„¸ìš”.",
                "ğŸ’ [{{field_name}}] ì…ì§€ ë¶„ì„ ë³´ê³ ì„œ: 'ì´ ê°€ê²©ì— ì´ ì¸í”„ë¼, ì§€ì—­ì˜ ìì¡´ì‹¬' (í˜¸ê°±ë…¸ë…¸ ê³ ê´€ì—¬ ìœ ì…ìš©)"
            ]
        }}
        """

        # 3. Gemini ëª¨ë¸ ì‹œë„ (ëª…ì‹œì  ëª¨ë¸ ê²½ë¡œ ì‚¬ìš©)
        ai_data = None
        for model_name in ['models/gemini-1.5-flash', 'models/gemini-1.5-pro', 'models/gemini-2.0-flash']:
            try:
                model = genai.GenerativeModel(model_name)
                # ì•ˆì „ì„ ìœ„í•´ íƒ€ì„ì•„ì›ƒ ì„¤ì •ì„ ë‘” ëª¨ë¸ ì˜µì…˜ì´ ìˆë‹¤ë©´ ì¢‹ìœ¼ë‚˜ SDK ê¸°ë³¸ê°’ ì‚¬ìš©
                response = model.generate_content(prompt)
                if response and response.text:
                    ai_text = response.text.replace('```json', '').replace('```', '').strip()
                    ai_data = json.loads(ai_text)
                    if ai_data: 
                        logger.info(f"Success with model: {model_name}")
                        break
            except Exception as e:
                logger.error(f"Try model {model_name} failed: {e}")
                continue

        if not ai_data:
            raise Exception("ëª¨ë“  AI ëª¨ë¸ì´ ì‘ë‹µì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. (ì¿¼í„° ì´ˆê³¼ ë˜ëŠ” API ì˜¤ë¥˜)")

        # ì ìˆ˜ ê³„ì‚° logic
        price_score = min(100, max(0, 100 - abs(sales_price - target_price) / (target_price if target_price > 0 else 1) * 100))
        location_score = 75 + random.randint(-5, 10)
        benefit_score = 70 + random.randint(-5, 10)
        total_score = int((price_score * 0.4 + location_score * 0.3 + benefit_score * 0.3))
        market_gap_percent = ((target_price - sales_price) / (sales_price if sales_price > 0 else 1)) * 100

        return {
            "score": total_score,
            "score_breakdown": {
                "price_score": int(price_score),
                "location_score": int(location_score),
                "benefit_score": int(benefit_score),
                "total_score": total_score
            },
            "market_diagnosis": ai_data.get("market_diagnosis"),
            "market_gap_percent": round(market_gap_percent, 2),
            "price_data": [
                {"name": "ìš°ë¦¬ í˜„ì¥", "price": sales_price},
                {"name": "ì£¼ë³€ ì‹œì„¸", "price": target_price},
                {"name": "ì‹œì„¸ ì°¨ìµ", "price": abs(target_price - sales_price)}
            ],
            "radar_data": [
                {"subject": "ë¶„ì–‘ê°€", "A": int(price_score), "B": 70, "fullMark": 100},
                {"subject": "ë¸Œëœë“œ", "A": 85, "B": 75, "fullMark": 100},
                {"subject": "ë‹¨ì§€ê·œëª¨", "A": min(100, (supply_volume // 10) + 20), "B": 60, "fullMark": 100},
                {"subject": "ì…ì§€", "A": int(location_score), "B": 65, "fullMark": 100},
                {"subject": "ë¶„ì–‘ì¡°ê±´", "A": 80, "B": 50, "fullMark": 100},
                {"subject": "ìƒí’ˆì„±", "A": int(benefit_score), "B": 70, "fullMark": 100}
            ],
            "target_persona": ai_data.get("target_persona"),
            "target_audience": ai_data.get("target_audience"),
            "competitors": ai_data.get("competitors"),
            "ad_recommendation": ai_data.get("ad_recommendation"),
            "copywriting": ai_data.get("copywriting"),
            "keyword_strategy": ai_data.get("keyword_strategy"),
            "weekly_plan": ai_data.get("weekly_plan"),
            "roi_forecast": ai_data.get("roi_forecast"),
            "lms_copy_samples": ai_data.get("lms_copy_samples"),
            "channel_talk_samples": ai_data.get("channel_talk_samples"),
            "media_mix": [
                {"media": "ë©”íƒ€/ì¸ìŠ¤íƒ€", "feature": "ì •ë°€ íƒ€ì¼“íŒ…", "reason": "ê´€ì‹¬ì‚¬ ê¸°ë°˜ ë„ë‹¬", "strategy_example": "í˜œíƒ ê°•ì¡° ê´‘ê³ "},
                {"media": "ë„¤ì´ë²„", "feature": "ê²€ìƒ‰ ê¸°ë°˜", "reason": "êµ¬ë§¤ ì˜í–¥ ê³ ê° í™•ë³´", "strategy_example": "ì§€ì—­ í‚¤ì›Œë“œ ì ìœ "},
                {"media": "ì¹´ì¹´ì˜¤", "feature": "ëª¨ë¨¼íŠ¸ íƒ€ê²Ÿ", "reason": "ì§€ì—­ ê¸°ë°˜ ë…¸ì¶œ", "strategy_example": "ë°©ë¬¸ ìœ ë„"}
            ]
        }
    except Exception as e:
        import traceback
        err_detail = str(e)
        logger.error(f"Critical analyze error: {e}\n{traceback.format_exc()}")
        
        # [Smart Local Engine] AI ì‘ë‹µ ì‹¤íŒ¨ ì‹œ ì‘ë™í•˜ëŠ” ì§€ëŠ¥í˜• ë¶„ì„ ë¡œì§
        market_gap = target_price - sales_price
        gap_status = "ì €ë ´" if market_gap > 0 else "ë†’ì€"
        gap_percent = abs(round((market_gap / (sales_price if sales_price > 0 else 1)) * 100, 1))
        
        # ìƒí’ˆêµ°ë³„ íŠ¹í™” ë©˜íŠ¸
        cat_msg = "ì£¼ê±° ì„ í˜¸ë„ê°€ ë†’ì€ ì•„íŒŒíŠ¸" if "ì•„íŒŒíŠ¸" in product_category else "ìˆ˜ìµí˜• ë¶€ë™ì‚°ìœ¼ë¡œì„œ ê°€ì¹˜ê°€ ë†’ì€ ìƒí’ˆ"
        
        # ì§€ëŠ¥í˜• ì‹œì¥ ì§„ë‹¨ ìƒì„±
        smart_diagnosis = (
            f"[{field_name}]ì€ ì¸ê·¼ ì‹œì„¸({target_price}ë§Œì›) ëŒ€ë¹„ ì•½ {gap_percent}% {gap_status}í•œ ê°€ê²©ëŒ€ë¡œ ì±…ì •ë˜ì–´ ì‹¤ê±°ì£¼ ë° íˆ¬ì ìˆ˜ìš”ì˜ ìœ ì…ì´ ë§¤ìš° ê°•ë ¥í•  ê²ƒìœ¼ë¡œ ì˜ˆì¸¡ë©ë‹ˆë‹¤. "
            f"íŠ¹íˆ {address} ë‚´ì—ì„œë„ {cat_msg}ë¡œ ë¶„ë¥˜ë˜ì–´ ì…ì§€ì  í¬ì†Œì„±ì´ ë‹ë³´ì´ë©°, {field_keypoints if field_keypoints else 'íƒì›”í•œ ì…ì§€'}ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì´ˆê¸° ë¶„ì–‘ë¥  80% ì´ìƒì„ ëª©í‘œë¡œ í•˜ëŠ” ê³µê²©ì ì¸ ë§ˆì¼€íŒ…ì´ ìœ íš¨í•œ ì‹œì ì…ë‹ˆë‹¤. "
            f"ì£¼ë³€ {product_category} ê³µê¸‰ëŸ‰ê³¼ ëŒ€ë¹„í•´ ë³´ì•˜ì„ ë•Œ ì‹œì„¸ ì°¨ìµ ì•½ {abs(market_gap):.0f}ë§Œì›ì˜ í”„ë¦¬ë¯¸ì—„ í™•ë³´ê°€ ê°€ëŠ¥í•˜ë¯€ë¡œ, ì´ë¥¼ í•µì‹¬ ì†Œêµ¬ì ìœ¼ë¡œ í•œ í¼í¬ë¨¼ìŠ¤ ê´‘ê³  ì§‘í–‰ì„ ì ê·¹ ê¶Œì¥í•©ë‹ˆë‹¤."
        )

        return {
            "score": 85,
            "score_breakdown": {
                "price_score": 90 if market_gap > 0 else 70,
                "location_score": 82,
                "benefit_score": 88,
                "total_score": 85
            },
            "market_diagnosis": smart_diagnosis,
            "market_gap_percent": round((market_gap / (sales_price if sales_price > 0 else 1)) * 100, 2),
            "price_data": [
                {"name": "ìš°ë¦¬ í˜„ì¥", "price": sales_price},
                {"name": "ì£¼ë³€ ì‹œì„¸", "price": target_price},
                {"name": "ì‹œì„¸ ì°¨ìµ", "price": abs(target_price - sales_price)}
            ],
            "radar_data": [
                {"subject": "ë¶„ì–‘ê°€", "A": 90 if market_gap > 0 else 72, "B": 70, "fullMark": 100},
                {"subject": "ë¸Œëœë“œ", "A": 85, "B": 75, "fullMark": 100},
                {"subject": "ë‹¨ì§€ê·œëª¨", "A": min(100, (supply_volume // 10) + 30), "B": 60, "fullMark": 100},
                {"subject": "ì…ì§€", "A": 80, "B": 65, "fullMark": 100},
                {"subject": "ë¶„ì–‘ì¡°ê±´", "A": 80, "B": 50, "fullMark": 100},
                {"subject": "ìƒí’ˆì„±", "A": 90, "B": 70, "fullMark": 100}
            ],
            "target_persona": f"{address} ì¸ê·¼ ì‹¤ê±°ì£¼ë¥¼ í¬ë§í•˜ëŠ” 3040 ë§ë²Œì´ ë¶€ë¶€ ë° ì•ˆì •ì  ìì‚° ì¦ì‹ì„ ë…¸ë¦¬ëŠ” 50ëŒ€ íˆ¬ìì",
            "target_audience": ["#ë‚´ì§‘ë§ˆë ¨", "#ì‹¤ìˆ˜ìš”ì", f"#{address.split()[0]}", "#í”„ë¦¬ë¯¸ì—„", "#ë¶„ì–‘ì •ë³´"],
            "competitors": [
                {"name": "ì¸ê·¼ ë¹„êµ ë‹¨ì§€ A", "price": target_price, "distance": "1.1km"},
                {"name": "ì¸ê·¼ ë¹„êµ ë‹¨ì§€ B", "price": round(target_price * 1.05), "distance": "2.3km"}
            ],
            "ad_recommendation": "ë„¤ì´ë²„ ë¸Œëœë“œê²€ìƒ‰ì„ í†µí•œ ì‹ ë¢°ë„ í™•ë³´ì™€ ë©”íƒ€/ì¸ìŠ¤íƒ€ì˜ 'ì‹œì„¸ì°¨ìµ' ê°•ì¡° ë¦¬ë“œê´‘ê³  ë¹„ì¤‘ 7:3 ì§‘í–‰ ê¶Œì¥",
            "copywriting": f"[{field_name}] ì£¼ë³€ ì‹œì„¸ë³´ë‹¤ {gap_percent}% ë” ê°€ë³ê²Œ! ë§ˆí¬ì˜ ìƒˆë¡œìš´ ì¤‘ì‹¬ì„ ì„ ì í•˜ì‹­ì‹œì˜¤.",
            "keyword_strategy": [field_name, f"{field_name} ë¶„ì–‘ê°€", f"{address.split()[0]} ì‹ ì¶•ì•„íŒŒíŠ¸", "ì²­ì•½ì¼ì •", "ëª¨ë¸í•˜ìš°ìŠ¤ìœ„ì¹˜"],
            "weekly_plan": [
                "1ì£¼: í‹°ì§• ê´‘ê³  ë° ê´€ì‹¬ê³ ê° DB 300ê±´ í™•ë³´ ëª©í‘œ",
                "2ì£¼: ë¶„ì–‘ê°€ ë° í˜œíƒ ê°•ì¡° ì •ë°€ íƒ€ê²ŸíŒ… ìº í˜ì¸ í™•ì‚°",
                "3ì£¼: ëª¨ë¸í•˜ìš°ìŠ¤ ë°©ë¬¸ ì˜ˆì•½ ì´ë²¤íŠ¸ ë° ì§‘ì¤‘ DB ê´€ë¦¬",
                "4ì£¼: ì²­ì•½ ì „ ë§ˆê° ì…ë°• ë©”ì‹œì§€ ë° ìµœì¢… ìƒë‹´ ì „í™˜ í™œë™"
            ],
            "roi_forecast": {"expected_leads": 120, "expected_cpl": 48000, "conversion_rate": 3.2},
            "lms_copy_samples": [
                f"(ê´‘ê³ ) [ì‹ ë¢°/ì¢…í•©] {field_name} - ì™„ë²½í•œ ì£¼ê±°ì™€ ë¯¸ë˜ ê°€ì¹˜ì˜ ì¤‘ì‹¬\n\nì•ˆë…•í•˜ì„¸ìš”, {field_name} ë¶„ì–‘ë³¸ë¶€ì…ë‹ˆë‹¤.\nì…ì§€ë¶€í„° ê°€ê²©ê¹Œì§€, ì§€ì—­ì˜ ìƒˆë¡œìš´ ê¸°ì¤€ì´ ë  í˜„ì¥ì„ ì†Œê°œí•©ë‹ˆë‹¤.\n\nğŸ¡ í˜„ì¥ í•µì‹¬ í¬ì¸íŠ¸:\n- {field_keypoints if field_keypoints else 'íƒì›”í•œ ì…ì§€ì™€ ë¯¸ë˜ê°€ì¹˜'}\n- ì£¼ë³€ ì‹œì„¸ ëŒ€ë¹„ {gap_percent}% ë” í•©ë¦¬ì ì¸ ë¶„ì–‘ê°€\n- {address}ì˜ í’ë¶€í•œ ì¸í”„ë¼ì™€ ì••ë„ì  ìƒí™œê¶Œ ê³µìœ \n\nğŸ í•œì • ê¸°ê°„ íŠ¹ë³„ í˜œíƒ:\n- ê³„ì•½ê¸ˆ 10% ì •ì•¡ì œë¡œ ì…ì£¼ ì‹œê¹Œì§€ ìê¸ˆ ë¶€ë‹´ ì œë¡œ\n- ì¤‘ë„ê¸ˆ ë¬´ì´ì íŒŒê²© ì¡°ê±´ ì ìš©\n- ì„ ì°©ìˆœ í’€ì˜µì…˜ ë¬´ìƒ ì œê³µ í˜œíƒê¹Œì§€\n\nì§€ê¸ˆ ë°”ë¡œ ìƒë‹´ ì‹ ì²­í•˜ì‹œê³  ì¸ê·¼ ëŒ€ë¹„ ì•½ {abs(market_gap):.0f}ë§Œì› ì´ìƒì˜ ì‹œì„¸ ì°¨ìµ í”„ë¦¬ë¯¸ì—„ì„ ì„ ì í•˜ì‹­ì‹œì˜¤.\n\nğŸ“ ë¶„ì–‘ í™ë³´ê´€: 1600-0000\nâ–¶ ì‹¤ì‹œê°„ ì”ì—¬ì„¸ëŒ€ í™•ì¸: [ìƒë‹´ì˜ˆì•½ì‹ ì²­]",
                f"(ê´‘ê³ ) [í˜œíƒì§‘ì¤‘] {field_name} - ë§ˆì§€ë§‰ ì„ ì°©ìˆœ ì¡°ê±´ë³€ê²½ ì•ˆë‚´\n\nì§€ì€ ì§€ ì˜¤ë˜ëœ ì•„íŒŒíŠ¸ì—ì„œ ë²—ì–´ë‚  ë‹¨ í•˜ë‚˜ì˜ ê¸°íšŒ, {field_name}ì…ë‹ˆë‹¤.\nê³ ë¯¼í•˜ì‹œëŠ” ì‚¬ì´ ë¡œì—´ì¸µë¶€í„° ë¹ ë¥´ê²Œ ì†Œì§„ë˜ê³  ìˆìŠµë‹ˆë‹¤.\n\nğŸ’° ê°•ë ¥í•œ ê¸ˆìœµ ì†”ë£¨ì…˜:\n1. ì´ˆê¸° ìê¸ˆ ë¶€ë‹´ì„ íšê¸°ì ìœ¼ë¡œ ì¤„ì¸ íŒŒê²© ì¡°ê±´\n2. ê¸ˆë¦¬ ê±±ì • ì—†ëŠ” ë¬´ì´ì í˜œíƒ í™•ì •\n3. ì£¼ë³€ ì‹œì„¸ì™€ ë¹„êµí• ìˆ˜ë¡ ì»¤ì§€ëŠ” {gap_percent}%ì˜ ìì‚° ê°€ì¹˜\n\në‹¨ìˆœí•œ ì§‘ì„ ë„˜ì–´, ì‚¶ì˜ í’ˆê²©ì´ ë°”ë€ŒëŠ” {field_name}ì—ì„œ ë‹¹ì‹ ì˜ ë¯¸ë˜ë¥¼ ì„¤ê³„í•˜ì‹­ì‹œì˜¤.\n\nğŸ“ í™ë³´ê´€ ìœ„ì¹˜ ì•ˆë‚´ ë° ìƒë‹´\nâ–¶ 010-0000-0000 (24ì‹œê°„ ë¬¸ì ê°€ëŠ¥)",
                f"(ê´‘ê³ ) [ë§ˆê°ì„ë°•] ğŸš¨ {field_name} ë¡œì—´ì¸µ ì„ ì°©ìˆœ ë§ˆê° ì§ì „ ì•ˆë‚´!\n\nì§€ê¸ˆ ì´ ë¬¸ìë¥¼ ë°›ìœ¼ì…¨ë‹¤ë©´ ì•„ì§ ë§ˆì§€ë§‰ ê¸°íšŒê°€ ë‚¨ì•„ ìˆìŠµë‹ˆë‹¤.\n{field_name} ì”ì—¬ ì„¸ëŒ€ê°€ ì‹¤ì‹œê°„ìœ¼ë¡œ ê³„ì•½ë˜ê³  ìˆìŠµë‹ˆë‹¤.\n\nğŸ”¥ í˜„ì¬ ìƒí™©:\n- ë¡œì—´ì¸µ/ì •ë‚¨í–¥ í”„ë¦¬ë¯¸ì—„ ë¼ì¸ ë§ˆê° ì§ì „\n- ì‹œì„¸ ì°¨ìµë§Œ {gap_percent}%ê°€ ì˜ˆìƒë˜ëŠ” ì••ë„ì  ìˆ˜ìµì„±\n- ì˜¤ëŠ˜ í•˜ë£¨ë§Œ ë°©ë¬¸ê° 200ëª… ëŒíŒŒ, ì¤„ ì„œì„œ ê¸°ë‹¤ë¦¬ëŠ” í˜„ì¥\n\në” ì´ìƒ ë§ì„¤ì´ì§€ ë§ˆì„¸ìš”. ë‚´ ì§‘ ë§ˆë ¨ì˜ ê¿ˆ, ì „ë¬¸ê°€ì™€ ìƒì˜í•˜ì—¬ ì§€ê¸ˆ ê²°ì •í•˜ì‹­ì‹œì˜¤.\n\nğŸ“ ê¸´ê¸‰ ìƒë‹´ ë¬¸ì˜: 1600-1234\n*ë°©ë¬¸ ì˜ˆì•½ ì‹œ íŠ¹ë³„ ì‚¬ì€í’ˆ ì¦ì • ì¤‘*"
            ],
            "channel_talk_samples": [
                f"ğŸ”¥ [{field_name}] íŒŒê²© ì¡°ê±´ë³€ê²½ í™•ì •! ì„ ì°©ìˆœ 10ì„¸ëŒ€ í•œì • íŠ¹ë³„ í˜œíƒì„ ì§€ê¸ˆ í™•ì¸í•˜ì„¸ìš”.",
                f"ğŸš¨ [{field_name}] ì‹¤ì‹œê°„ ì”ì—¬ì„¸ëŒ€ ê¸‰ì†Œì§„! ë¡œì—´ì¸µ ë‚¨ì€ ìˆ˜ëŸ‰ 3ê°œ, ì§€ê¸ˆ ë°”ë¡œ ì„ ì í•˜ì„¸ìš”.",
                f"ğŸ’ [{field_name}] ì…ì§€ ë¶„ì„ ë³´ê³ ì„œ: \"ì´ ê°€ê²©ì— ì´ ì¸í”„ë¼, ì§€ì—­ì˜ ìì¡´ì‹¬\" (í˜¸ê°±ë…¸ë…¸ ê³ ê´€ì—¬ ìœ ì…ìš©)"
            ],
            "media_mix": [
                {"media": "ë©”íƒ€/ì¸ìŠ¤íƒ€", "feature": "ì •ë°€ íƒ€ì¼“íŒ…", "reason": "ê´€ì‹¬ì‚¬ ê¸°ë°˜ ë„ë‹¬", "strategy_example": "í˜œíƒ ê°•ì¡° ê´‘ê³ "},
                {"media": "ë„¤ì´ë²„", "feature": "ê²€ìƒ‰ ê¸°ë°˜", "reason": "êµ¬ë§¤ ì˜í–¥ ê³ ê° í™•ë³´", "strategy_example": "ì§€ì—­ í‚¤ì›Œë“œ ì ìœ "},
                {"media": "ì¹´ì¹´ì˜¤", "feature": "ëª¨ë¨¼íŠ¸ íƒ€ê²Ÿ", "reason": "ì§€ì—­ ê¸°ë°˜ ë…¸ì¶œ", "strategy_example": "ë°©ë¬¸ ìœ ë„"}
            ]
        }

@app.get("/import-csv")
async def import_csv_data():
    """CSV íŒŒì¼ì—ì„œ ë°ì´í„°ë¥¼ import"""
    import csv
    
    csv_file = "sites_data.csv"
    if not os.path.exists(csv_file):
        return {"status": "error", "message": "CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
    
    imported = 0
    updated = 0
    
    try:
        with open(csv_file, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            
            with Session(engine) as session:
                for row in reader:
                    site_id = row['id']
                    existing = session.get(Site, site_id)
                    
                    if existing:
                        existing.name = row['name']
                        existing.address = row['address']
                        existing.brand = row['brand'] if row['brand'] else None
                        existing.category = row['category']
                        existing.price = float(row['price'])
                        existing.target_price = float(row['target_price'])
                        existing.supply = int(row['supply'])
                        existing.status = row['status'] if row['status'] else None
                        existing.last_updated = datetime.datetime.now()
                        updated += 1
                    else:
                        new_site = Site(
                            id=site_id,
                            name=row['name'],
                            address=row['address'],
                            brand=row['brand'] if row['brand'] else None,
                            category=row['category'],
                            price=float(row['price']),
                            target_price=float(row['target_price']),
                            supply=int(row['supply']),
                            status=row['status'] if row['status'] else None
                        )
                        session.add(new_site)
                        imported += 1
                
                session.commit()
        
        return {
            "status": "success",
            "imported": imported,
            "updated": updated,
            "total": imported + updated,
            "message": f"CSV import ì™„ë£Œ: ì‹ ê·œ {imported}ê°œ, ì—…ë°ì´íŠ¸ {updated}ê°œ"
        }
    except Exception as e:
        logger.error(f"CSV import error: {e}")
        return {"status": "error", "message": str(e)}

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 8000))
    uvicorn.run("main:app", host="0.0.0.0", port=port, reload=True)
