from fastapi import FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Optional
import random
import datetime
import os
import uvicorn
import asyncio
from contextlib import asynccontextmanager
from sqlmodel import Field, Session, SQLModel, create_engine, select, or_, col
import logging
import httpx
import google.generativeai as genai
import json
from typing import List, Optional, Union, Any

# Gemini API ì„¤ì •
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "AIzaSyCpLoq9OIzHB5Z0xJyXbUrALsh4ePqgVV0")
genai.configure(api_key=GEMINI_API_KEY)

import logging
import re

# êµ¬ê¸€ ì‹œíŠ¸ ì›¹í›… URL (ì‚¬ìš©ìê°€ ì„¤ì •í•œ URL)
GOOGLE_SHEET_WEBHOOK_URL = "https://script.google.com/macros/s/AKfycbzZLa5HVuEdHpoD3ip6908XGyagJFsfsfJAmlfxLOekrqad0625QbYV4TLai4xHswwDfw/exec"
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def extract_json(text: str):
    """ë¬¸ìì—´ì—ì„œ JSON ë¸”ë¡ë§Œ ì¶”ì¶œí•˜ëŠ” ê³ ë„í™”ëœ í•¨ìˆ˜ (RegEx ì‚¬ìš©)"""
    if not text:
        return None
    
    # 1. ```json ë¸”ë¡ ì¶”ì¶œ ì‹œë„
    match = re.search(r"```json\s*(\{.*?\})\s*```", text, re.DOTALL)
    if match:
        try:
            return json.loads(match.group(1).strip())
        except: pass
        
    # 2. ì¼ë°˜ ``` ë¸”ë¡ ì¶”ì¶œ ì‹œë„
    match = re.search(r"```\s*(\{.*?\})\s*```", text, re.DOTALL)
    if match:
        try:
            return json.loads(match.group(1).strip())
        except: pass

    # 3. í…ìŠ¤íŠ¸ ë‚´ì˜ ì²« ë²ˆì§¸ { ì™€ ë§ˆì§€ë§‰ } ì‚¬ì´ ì¶”ì¶œ ì‹œë„
    match = re.search(r"(\{.*\})", text, re.DOTALL)
    if match:
        try:
            return json.loads(match.group(1).strip())
        except: pass
        
    # 4. ì „ì²´ í…ìŠ¤íŠ¸ ì‹œë„
    try:
        return json.loads(text.strip())
    except:
        logger.error(f"Failed to parse AI JSON response: {text[:200]}...")
        return None

# --- Database Setup ---
sqlite_file_name = "database.db"
sqlite_url = f"sqlite:///{sqlite_file_name}"
engine = create_engine(sqlite_url, connect_args={"check_same_thread": False})

class Site(SQLModel, table=True):
    __table_args__ = {'extend_existing': True}
    
    id: str = Field(primary_key=True)
    name: str
    address: str
    brand: Optional[str] = None
    category: str
    price: float
    target_price: float
    supply: int
    status: Optional[str] = None
    last_updated: datetime.datetime = Field(default_factory=datetime.datetime.now)

class Lead(SQLModel, table=True):
    __table_args__ = {'extend_existing': True}
    id: Optional[int] = Field(default=None, primary_key=True)
    name: str
    phone: str
    rank: str
    site: str
    source: Optional[str] = Field(default="ì•Œ ìˆ˜ ì—†ìŒ")
    created_at: datetime.datetime = Field(default_factory=datetime.datetime.now)

# --- NATIONWIDE START DATA ---
MOCK_SITES = [
    {"id": "h_uj1", "name": "í•´ë§í„´ í”Œë ˆì´ìŠ¤ ì˜ì •ë¶€ì—­", "address": "ê²½ê¸°ë„ ì˜ì •ë¶€ì‹œ", "brand": "í•´ë§í„´", "category": "ì•„íŒŒíŠ¸", "price": 2300, "target_price": 2600, "supply": 612, "status": "ê³µê³ ì¢…ë£Œ"},
    {"id": "dj_doan1", "name": "íìŠ¤í…Œì´íŠ¸ ë„ì•ˆë¦¬ë²„íŒŒí¬ 1ë‹¨ì§€", "address": "ëŒ€ì „ê´‘ì—­ì‹œ ìœ ì„±êµ¬", "brand": "íìŠ¤í…Œì´íŠ¸", "category": "ì•„íŒŒíŠ¸", "price": 1950, "target_price": 2200, "supply": 1124, "status": "ë¶„ì–‘ì¤‘"},
    {"id": "jt1", "name": "ì˜ì •ë¶€ì—­ ìŠ¤ë§ˆíŠ¸ì‹œí‹°(ì§€ì—­ì£¼íƒì¡°í•©)", "address": "ê²½ê¸°ë„ ì˜ì •ë¶€ì‹œ", "brand": "ê¸°íƒ€", "category": "ì§€ì—­ì£¼íƒì¡°í•©", "price": 1500, "target_price": 1750, "supply": 1614, "status": "ì¡°í•©ì›ëª¨ì§‘"},
    {"id": "uj_topseok1", "name": "ì˜ì •ë¶€ íƒ‘ì„ ì„¼íŠ¸ëŸ´íŒŒí¬ í‘¸ë¥´ì§€ì˜¤", "address": "ê²½ê¸°ë„ ì˜ì •ë¶€ì‹œ íƒ‘ì„ë™", "brand": "í‘¸ë¥´ì§€ì˜¤", "category": "ì•„íŒŒíŠ¸", "price": 2400, "target_price": 2700, "supply": 840, "status": "ë¶„ì–‘ì˜ˆì •"},
    {"id": "uj_hoeryong1", "name": "ì˜ì •ë¶€ íšŒë£¡ íŒŒí¬ë·° ìì´", "address": "ê²½ê¸°ë„ ì˜ì •ë¶€ì‹œ íšŒë£¡ë™", "brand": "ìì´", "category": "ì•„íŒŒíŠ¸", "price": 2200, "target_price": 2500, "supply": 650, "status": "ë¶„ì–‘ì¤‘"},
    {"id": "uj_hoeryong2", "name": "íšŒë£¡ì—­ ë¡¯ë°ìºìŠ¬", "address": "ê²½ê¸°ë„ ì˜ì •ë¶€ì‹œ íšŒë£¡ë™", "brand": "ë¡¯ë°ìºìŠ¬", "category": "ì•„íŒŒíŠ¸", "price": 2350, "target_price": 2650, "supply": 720, "status": "ë¶„ì–‘ì˜ˆì •"},
    {"id": "uj_topseok2", "name": "íƒ‘ì„ì—­ íìŠ¤í…Œì´íŠ¸", "address": "ê²½ê¸°ë„ ì˜ì •ë¶€ì‹œ íƒ‘ì„ë™", "brand": "íìŠ¤í…Œì´íŠ¸", "category": "ì•„íŒŒíŠ¸", "price": 2450, "target_price": 2750, "supply": 890, "status": "ë¶„ì–‘ì¤‘"},
]

def create_db_and_tables():
    SQLModel.metadata.create_all(engine)
    
    # Migration: Add source column to lead table if it doesn't exist
    from sqlalchemy import text
    try:
        with engine.connect() as conn:
            # PRAGMA table_info returns (id, name, type, notnull, dflt_value, pk)
            columns = [row[1] for row in conn.execute(text("PRAGMA table_info(lead)")).fetchall()]
            if columns and 'source' not in columns:
                conn.execute(text("ALTER TABLE lead ADD COLUMN source TEXT DEFAULT 'ì•Œ ìˆ˜ ì—†ìŒ'"))
                conn.commit()
                logger.info("Database migration: Added 'source' column to 'lead' table.")
    except Exception as e:
        logger.error(f"Migration error: {e}")

    with Session(engine) as session:
        for s_data in MOCK_SITES:
            existing = session.get(Site, s_data["id"])
            if not existing:
                session.add(Site(**s_data))
            else:
                for key, value in s_data.items():
                    setattr(existing, key, value)
        session.commit()

@asynccontextmanager
async def lifespan(app: FastAPI):
    create_db_and_tables()
    # ì„œë²„ ì‹œì‘ ì‹œ CSV ë°ì´í„° ìë™ ë¡œë“œ (ë°ì´í„° ìœ ì‹¤ ë°©ì§€)
    try:
        import csv
        csv_file = "sites_data.csv"
        if os.path.exists(csv_file):
            with Session(engine) as session:
                with open(csv_file, 'r', encoding='utf-8') as f:
                    reader = csv.DictReader(f)
                    for row in reader:
                        site_id = row['id']
                        if not session.get(Site, site_id):
                            session.add(Site(
                                id=site_id,
                                name=row['name'],
                                address=row['address'],
                                brand=row['brand'] if row['brand'] else None,
                                category=row['category'],
                                price=float(row['price']),
                                target_price=float(row['target_price']),
                                supply=int(row['supply']),
                                status=row['status'] if row['status'] else None
                            ))
                    session.commit()
            logger.info("CSV data auto-imported on startup.")
    except Exception as e:
        logger.error(f"Startup data import error: {e}")
    yield

app = FastAPI(lifespan=lifespan)

# CORS ì„¤ì •ì„ ë” ëª…ì‹œì ìœ¼ë¡œ ê°•í™”
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["GET", "POST", "OPTIONS"],
    allow_headers=["*"],
    expose_headers=["*"],
)

class SiteSearchResponse(BaseModel):
    id: str
    name: str
    address: str
    status: Optional[str] = None
    brand: Optional[str] = None
    category: Optional[str] = None

@app.get("/search-sites", response_model=List[SiteSearchResponse])
async def search_sites(q: str):
    if not q or len(q) < 2:
        return []

    results = []
    seen_ids = set()
    q_lower = q.lower().strip()

    # 1. DB ê²€ìƒ‰ (ë¶„ì–‘ ë°ì´í„°ë² ì´ìŠ¤ ìš°ì„ )
    try:
        with Session(engine) as session:
            # ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´ ê²€ìƒ‰ (name, address, brand, category, status ëª¨ë‘ ê²€ìƒ‰)
            statement = select(Site).where(
                or_(
                    col(Site.name).ilike(f"%{q}%"), 
                    col(Site.address).ilike(f"%{q}%"), 
                    col(Site.brand).ilike(f"%{q}%"),
                    col(Site.category).ilike(f"%{q}%"),
                    col(Site.status).ilike(f"%{q}%")
                )
            ).order_by(col(Site.last_updated).desc()).limit(100)
            db_sites = session.exec(statement).all()
            for s in db_sites:
                if s.id not in seen_ids:
                    results.append(SiteSearchResponse(id=s.id, name=s.name, address=s.address, status=s.status, brand=s.brand, category=s.category))
                    seen_ids.add(s.id)
    except Exception as e:
        logger.error(f"DB search error: {e}")

    # 2. ì‹¤ì‹œê°„ ë¶„ì–‘ ì „ë¬¸ API ê²€ìƒ‰ (êµ¬ì¶• ì•„íŒŒíŠ¸ë¥¼ ì›ì²œ ë°°ì œí•˜ê¸° ìœ„í•´ isale APIë§Œ ì‚¬ìš©)
    try:
        async with httpx.AsyncClient(follow_redirects=True) as client:
            fake_nnb = "".join(random.choices("0123456789ABCDEF", k=16))
            h = {
                "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
                "Accept": "application/json, text/plain, */*",
                "Accept-Language": "ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7",
                "Accept-Encoding": "gzip, deflate, br",
                "Referer": "https://m.land.naver.com/",
                "Origin": "https://m.land.naver.com",
                "Cookie": f"NNB={fake_nnb}",
                "Sec-Fetch-Dest": "empty",
                "Sec-Fetch-Mode": "cors",
                "Sec-Fetch-Site": "same-site"
            }
            
            # ë¶„ì–‘ ì •ë³´ê°€ ìˆëŠ” 'isale' ë°ì´í„°ë² ì´ìŠ¤ë§Œ ì¡°íšŒ (ì˜¤ë˜ëœ ê¸°ì¶• ì•„íŒŒíŠ¸ëŠ” ì—¬ê¸°ì„œ ê±¸ëŸ¬ì§)
            url_isale = "https://isale.land.naver.com/iSale/api/complex/searchList"
            params = {
                "keyword": q, 
                "complexType": "APT:ABYG:JGC:OR:OP:VL:DDD:ABC:ETC:UR:HO:SH", 
                "salesStatus": "0:1:2:3:4:5:6:7:8:9:10:11:12", 
                "pageSize": "100"
            }
            res_isale = await client.get(url_isale, params=params, headers=h, timeout=3.0)
            if res_isale.status_code == 200:
                data = res_isale.json()
                for it in data.get("result", {}).get("list", []):
                    sid = f"extern_isale_{it.get('complexNo')}"
                    if sid not in seen_ids:
                        results.append(SiteSearchResponse(
                            id=sid, name=it.get('complexName'), address=it.get('address'), 
                            status=it.get('salesStatusName'), brand=it.get('h_name'),
                            category=it.get('complexTypeName', 'ì•„íŒŒíŠ¸')
                        ))
                        seen_ids.add(sid)
    except Exception as e:
        logger.error(f"API search error: {e}")

    # ê²€ìƒ‰ ê²°ê³¼ ì •ë ¬ - í˜„ì¥ëª…ì— ê²€ìƒ‰ì–´ê°€ í¬í•¨ëœ ê²½ìš° ìš°ì„  í‘œì‹œ
    def sort_key(x):
        name_lower = x.name.lower() if x.name else ""
        address_lower = x.address.lower() if x.address else ""
        
        # ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ê²½ìš° ìµœìš°ì„ 
        if name_lower == q_lower:
            return (0, 0)
        # í˜„ì¥ëª…ì´ ê²€ìƒ‰ì–´ë¡œ ì‹œì‘í•˜ëŠ” ê²½ìš°
        if name_lower.startswith(q_lower):
            return (1, name_lower.find(q_lower))
        # í˜„ì¥ëª…ì— ê²€ìƒ‰ì–´ê°€ í¬í•¨ëœ ê²½ìš°
        if q_lower in name_lower:
            return (2, name_lower.find(q_lower))
        # ì£¼ì†Œì— ê²€ìƒ‰ì–´ê°€ í¬í•¨ëœ ê²½ìš°
        if q_lower in address_lower:
            return (3, address_lower.find(q_lower))
        # ê·¸ ì™¸
        return (999, 999)
    
    results.sort(key=sort_key)
    logger.info(f"Search query: '{q}' returned {len(results)} results")
    return results[:100]

@app.get("/sync-all")
async def sync_all():
    # êµ¬ì¶•ì„ ì œì™¸í•œ ì „êµ­ì˜ 'ìµœê·¼ 5ë…„ ë‚´' ë¶„ì–‘/ì„ëŒ€/ì§€ì£¼íƒ ë¦¬ìŠ¤íŠ¸ í€€í…€ ë™ê¸°í™”
    keywords = [
        "í•´ë§í„´", "ì¨ë°‹", "ë””ì—íŠ¸ë¥´", "ì§€ì—­ì£¼íƒì¡°í•©", "ì§€ì£¼íƒ", "ë¯¸ë¶„ì–‘", "ì„ ì°©ìˆœ",
        "ëŒ€ì „", "ì˜ì •ë¶€", "ë¶€ì‚°", "ì„œìš¸", "ì¸ì²œ", "ê²½ê¸°", "ìˆ˜ì›", "ì„±ë‚¨",
        "íƒ‘ì„", "íšŒë£¡", "íŒŒí¬ë·°", "íìŠ¤í…Œì´íŠ¸", "ìì´", "í‘¸ë¥´ì§€ì˜¤", "eí¸í•œì„¸ìƒ",
        "ë¡¯ë°ìºìŠ¬", "ì•„ì´íŒŒí¬", "ë”ìƒµ", "ì„¼íŠ¸ëŸ´", "í¬ë ˆìŠ¤íŠ¸", "ë ˆì´í¬", "ìŠ¤ì¹´ì´"
    ]
    count = 0
    async with httpx.AsyncClient() as client:
        for kw in keywords:
            try:
                fake_nnb = "".join(random.choices("0123456789ABCDEF", k=16))
                h = {"User-Agent": "Mozilla/5.0", "Cookie": f"NNB={fake_nnb}"}
                url = "https://isale.land.naver.com/iSale/api/complex/searchList"
                params = {"keyword": kw, "complexType": "APT:ABYG:JGC:OR:OP:VL:DDD:ABC:ETC:UR:HO:SH", "salesStatus": "0:1:2:3:4:5:6:7:8:9:10:11:12", "pageSize": "100"}
                res = await client.get(url, params=params, headers=h, timeout=8.0)
                if res.status_code == 200:
                    items = res.json().get("result", {}).get("list", [])
                    with Session(engine) as session:
                        for it in items:
                            sid = f"extern_isale_{it.get('complexNo')}"
                            if not session.get(Site, sid):
                                session.add(Site(
                                    id=sid, name=it.get("complexName"), address=it.get("address"),
                                    brand=it.get("h_name"), category=it.get("complexTypeName", "ë¶€ë™ì‚°"),
                                    price=1900.0, target_price=2200.0, supply=500, status=it.get("salesStatusName")
                                ))
                                count += 1
                        session.commit()
                await asyncio.sleep(0.3)
            except: pass
    return {"status": "sync_completed", "new_items": count, "message": "ë¶„ì–‘/ì„ëŒ€/ì§€ì£¼íƒ ì „ë¬¸ ë°ì´í„° ë™ê¸°í™”ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. (êµ¬ì¶• ì œì™¸)"}

@app.get("/site-details/{site_id}")
async def get_site_details(site_id: str):
    with Session(engine) as session:
        site = session.get(Site, site_id)
        if site: return site
        return {"id": site_id, "name": "ë¶„ì–‘ ë¶„ì„ ì™„ë£Œ", "address": "ì§€ì—­ ì •ë³´", "brand": "ê¸°íƒ€", "category": "ë¶€ë™ì‚°", "price": 2500, "target_price": 2800, "supply": 500, "status": "ë°ì´í„° ë¡œë“œ"}

class AnalyzeRequest(BaseModel):
    field_name: Optional[str] = "ì•Œ ìˆ˜ ì—†ëŠ” í˜„ì¥"
    address: Optional[str] = "ì§€ì—­ ì •ë³´ ì—†ìŒ"
    product_category: Optional[str] = "ì•„íŒŒíŠ¸"
    sales_stage: Optional[str] = "ë¶„ì–‘ì¤‘"
    down_payment: Optional[Union[int, str]] = "10%"
    interest_benefit: Optional[str] = "ì—†ìŒ"
    additional_benefits: Optional[Union[List[str], str]] = []
    main_concern: Optional[str] = "ê¸°íƒ€"
    monthly_budget: Optional[Union[int, float]] = 0
    existing_media: Optional[Union[List[str], str]] = []
    sales_price: Optional[float] = 0.0
    target_area_price: Optional[float] = 0.0
    down_payment_amount: Optional[Union[int, float]] = 0
    supply_volume: Optional[Union[int, str]] = 0
    field_keypoints: Optional[str] = ""
    user_email: Optional[str] = None

class RegenerateCopyResponse(BaseModel):
    lms_copy_samples: List[str]
    channel_talk_samples: List[str]

@app.post("/regenerate-copy", response_model=RegenerateCopyResponse)
async def regenerate_copy(req: AnalyzeRequest):
    """ì¹´í”¼ ì¬ìƒì„± ì „ìš© ì—”ë“œí¬ì¸íŠ¸"""
    field_name = req.field_name or "ë¶„ì„ í˜„ì¥"
    address = req.address or "ì§€ì—­ ì •ë³´"
    gap = (float(req.target_area_price or 0) - float(req.sales_price or 0)) / (float(req.sales_price or 1) if req.sales_price and req.sales_price > 0 else 1)
    gap_percent = round(gap * 100, 1)
    
    # ë°ì´í„° ì•ˆì „í•˜ê²Œ ì¶”ì¶œ
    dp = str(req.down_payment) if req.down_payment else "10%"
    ib = req.interest_benefit or "ë¬´ì´ì"
    fkp = req.field_keypoints or "íƒì›”í•œ ì…ì§€ì™€ ë¯¸ë˜ê°€ì¹˜"

    # ì‹¤ì „ ë ˆí¼ëŸ°ìŠ¤ ìŠ¤íƒ€ì¼ì˜ 3ì¢… ëŸ­ì…”ë¦¬ í…œí”Œë¦¿
    lms_samples = [
        f"ã€{field_name}ã€‘\n\nğŸ”¥ íŒŒê²©ì¡°ê±´ë³€ê²½!!\nâ˜› ê³„ì•½ê¸ˆ {dp}\nâ˜› {ib} íŒŒê²© í˜œíƒ\nâ˜› ì‹¤ê±°ì£¼ì˜ë¬´ ë° ì²­ì•½í†µì¥ ç„¡\n\nâ–  ì´ˆí˜„ëŒ€ì  ì…ì§€+íŠ¸ë¦¬í”Œ êµí†µë§\nğŸš… GTX ë° ì£¼ìš” ë…¸ì„  ì—°ì¥ ìˆ˜í˜œ(ì˜ˆì •)\nğŸ« ë‹¨ì§€ ë°”ë¡œ ì• ì´ˆÂ·ì¤‘Â·ê³  ë„ë³´ í•™ì„¸ê¶Œ\nğŸ™ï¸ {address} í•µì‹¬ ì¸í”„ë¼ ì›ìŠ¤í†± ë¼ì´í”„\n\nâ–  ë¸Œëœë“œ & ìì‚° ê°€ì¹˜\nâ–¶ ì£¼ë³€ ì‹œì„¸ ëŒ€ë¹„ {gap_percent}% ë‚®ì€ ì••ë„ì  ë¶„ì–‘ê°€\nâ–¶ {fkp} íŠ¹í™” ì„¤ê³„ ì ìš©\nâ–¶ ëŒ€ë‹¨ì§€ í”„ë¦¬ë¯¸ì—„ ëœë“œë§ˆí¬ ìŠ¤ì¼€ì¼\n\nğŸ ì˜ˆì•½ í›„ ë°©ë¬¸ ì‹œ 'ì‹ ì„¸ê³„ ìƒí’ˆê¶Œ' ì¦ì •\nğŸ‰ ê³„ì•½ ì‹œ 'ê³ ê¸‰ ê°€ì „ ì‚¬ì€í’ˆ' íŠ¹ë³„ ì¦ì •\nâ˜ï¸ ë¬¸ì˜ : 1600-0000",
        f"[íŠ¹ë³„ê³µì‹ë°œì†¡] {field_name} ê´€ì‹¬ê³ ê° ì•ˆë‚´\n(ì „ì„¸ëŒ€ ì„ í˜¸ë„ ë†’ì€ 84ã¡ ìœ„ì£¼ êµ¬ì„±)\n\nğŸ’° ê°•ë ¥í•œ ê¸ˆìœµ í˜œíƒ\nâœ… ê³„ì•½ê¸ˆ {dp} (1ì°¨)\nâœ… ì¤‘ë„ê¸ˆ 60% {ib}\nâœ… ë¬´ì œí•œ ì „ë§¤ ê°€ëŠ¥ ë‹¨ì§€\n\nğŸ¡ í˜„ì¥ íŠ¹ì¥ì \n- {address} ë‚´ ë§ˆì§€ë§‰ ë…¸ë‹¤ì§€ í•µì‹¬ ì…ì§€\n- {gap_percent}% ì´ìƒì˜ í™•ì‹¤í•œ ì‹œì„¸ ì°¨ìµ ê¸°ëŒ€\n- {fkp} ë“± ê³ í’ˆê²© ì»¤ë®¤ë‹ˆí‹° ì‹œì„¤\n- ë„ë³´ê¶Œ ëª…í’ˆ í•™ì›ê°€ ë° ëŒ€í˜• ë§ˆíŠ¸ ì¸ì ‘\n\në” ì´ìƒ ë§ì„¤ì´ì§€ ë§ˆì„¸ìš”. ë§ˆì§€ë§‰ ë¡œì—´ì¸µì´ ì†Œì§„ ì¤‘ì…ë‹ˆë‹¤.\nâ˜ï¸ ìƒë‹´ë¬¸ì˜: 010-0000-0000",
        f"ğŸš¨ {field_name} ì œë¡œê³„ì•½ê¸ˆ ìˆ˜ì¤€ ë§ˆê° ì„ë°•!\n\nğŸ”¥ ì „ì„¸ëŒ€ ì˜êµ¬ ì¡°ë§ ë° í”„ë¦¬ë¯¸ì—„ íŠ¹í™” ì„¤ê³„\nğŸ”¥ í˜„ì¬ ì¸ê¸° íƒ€ì… ì™„íŒ ì§ì „, ì”ì—¬ ì†Œìˆ˜ ë¶„ì–‘\nğŸ”¥ {ib}, ì£¼íƒìˆ˜ ë¯¸í¬í•¨ ìˆ˜í˜œ ë‹¨ì§€\n\nğŸš— ì‚¬í†µíŒ”ë‹¬ êµí†µë§ í™•ì • ë° ì„œìš¸ ì ‘ê·¼ì„± í˜ì‹ \nğŸï¸ ëŒ€í˜• ê³µì›ê³¼ ìˆ˜ë³€ ì¡°ë§ì„ í’ˆì€ ìˆ²ì„¸ê¶Œ/ë¬¼ì„¸ê¶Œ\nğŸ—ï¸ ì¸ì ‘ ëŒ€ê·œëª¨ ê°œë°œ í˜¸ì¬ë¡œ ì¸í•œ ë¯¸ë˜ ê°€ì¹˜ ê¸‰ìƒìŠ¹\n\nğŸ ì„ ì°©ìˆœ ê³„ì•½ì¶•í•˜ ì´ë²¤íŠ¸ ì§„í–‰ ì¤‘\nì˜ˆì•½ ë°©ë¬¸ë§Œ í•´ë„ 'ê³ ê¸‰ ì™€ì¸ ë° ì‚¬ì€í’ˆ' ì¦ì •\nğŸ“ ëŒ€í‘œë²ˆí˜¸: 1811-0000"
    ]

    channel_samples = [
        f"ğŸ”¥ {field_name} | íŒŒê²© ì¡°ê±´ë³€ê²½ ì†Œì‹!\n\ní˜„ì¬ í˜¸ê°±ë…¸ë…¸ì—ì„œ ê°€ì¥ ëœ¨ê±°ìš´ ê´€ì‹¬ì„ ë°›ëŠ” ì´ìœ , ë“œë””ì–´ ê³µê°œí•©ë‹ˆë‹¤! ğŸ’\n\nâœ… í•µì‹¬ í˜œíƒ ìš”ì•½:\n- ê³„ì•½ê¸ˆ {dp} (ì…ì£¼ ì „ ì „ë§¤ ê°€ëŠ¥)\n- ì´ì ë¶€ë‹´ ì œë¡œ! {ib} í˜œíƒ í™•ì •\n- ì¸ê·¼ ì‹œì„¸ ëŒ€ë¹„ {gap_percent}% ë‚®ì€ ì••ë„ì  ì €í‰ê°€ ë‹¨ì§€\n\n'ì´ ê°€ê²©ì— ì´ ì¸í”„ë¼ê°€ ì •ë§ì¸ê°€ìš”?' ë¼ëŠ” ë¬¸ì˜ê°€ ë¹—ë°œì¹˜ê³  ìˆìŠµë‹ˆë‹¤. ğŸš… ê´‘ì—­ êµí†µë§ì˜ ìµœì¤‘ì‹¬, {address}ì˜ ëœë“œë§ˆí¬ë¥¼ ì§€ê¸ˆ ë°”ë¡œ ì„ ì í•˜ì‹­ì‹œì˜¤.\n\nğŸ“¢ ì‹¤ì‹œê°„ ë¡œì—´ì¸µ ì”ì—¬ ìˆ˜ëŸ‰ í™•ì¸ ë° ì •ë°€ ì…ì§€ ë¦¬í¬íŠ¸ ì‹ ì²­í•˜ê¸° ğŸ‘‡\nâ˜ï¸ ëŒ€í‘œë¬¸ì˜ : 1600-0000",
        f"ğŸš¨ [ê¸´ê¸‰] {field_name} ë¡œì—´ì¸µ ì„ ì°©ìˆœ ë§ˆê° ì§ì „!\n\në§ì„¤ì´ëŠ” ìˆœê°„ ê¸°íšŒëŠ” ì§€ë‚˜ê°‘ë‹ˆë‹¤. í˜„ì¬ {field_name} í˜„ì¥ì€ ì‹¤ì‹œê°„ ì˜ˆì•½ í­ì£¼ë¡œ ë¡œì—´ì¸µ ë¬¼ëŸ‰ì´ ì¾Œì† ì†Œì§„ë˜ê³  ìˆìŠµë‹ˆë‹¤! ğŸ’¨\n\nğŸ’ ì™œ ì§€ê¸ˆ {field_name}ì¸ê°€?\n1. {address} ë‚´ ë§ˆì§€ë§‰ ë…¸ë‹¤ì§€ í™©ê¸ˆ ì…ì§€\n2. ì‹œì„¸ ì°¨ìµë§Œ {gap_percent}%ê°€ ì˜ˆìƒë˜ëŠ” íˆ¬ìê°€ì¹˜\n3. {fkp} ë“± ë¸Œëœë“œë§Œì˜ ê³ í’ˆê²© íŠ¹í™” ì„¤ê³„\n\nì§€ê¸ˆ ë°”ë¡œ ìƒë‹´ ì˜ˆì•½ ì‹œ 'ëª¨ë¸í•˜ìš°ìŠ¤ í•˜ì´íŒ¨ìŠ¤ ìš°ì„  ì…ì¥'ê³¼ 'íŠ¹ë³„ ì‚¬ì€í’ˆ' í˜œíƒì„ ì±™ê²¨ë“œë¦½ë‹ˆë‹¤. ğŸ\n\nğŸ“ ê¸´ê¸‰ ìƒë‹´ ë° ë°©ë¬¸ì˜ˆì•½: 010-0000-0000",
        f"ğŸ“Š {field_name} ê³ ê´€ì—¬ ì‹¤ê±°ì£¼ìš© [ì •ë°€ ë¶„ì„ ë¦¬í¬íŠ¸] ë°°í¬\n\ní˜¸ê°±ë…¸ë…¸ ìœ ì €ë¶„ë“¤ì´ ì£¼ëª©í•˜ëŠ” ì§„ì§œ ì •ë³´ë¥¼ ë¶„ì„í–ˆìŠµë‹ˆë‹¤. ğŸ§\në‹¨ìˆœ ê´‘ê³ ê°€ ì•„ë‹Œ, í•™êµ°/ìƒê¶Œ/êµí†µ í˜¸ì¬ë¥¼ íŒ©íŠ¸ë¡œ ì •ë¦¬í•œ ìœ ë£Œê¸‰ ë¦¬í¬íŠ¸ë¥¼ ë¬´ë£Œ ì œê³µí•©ë‹ˆë‹¤.\n\nâœ¨ ë¦¬í¬íŠ¸ ì£¼ìš” í¬ì¸íŠ¸:\n- {address} ê¶Œì—­ í–¥í›„ ìˆ˜ê¸‰ ë° ì‹œì„¸ ì „ë§\n- ì¸ê·¼ ëŒ€ë¹„ {gap_percent}% ì €ë ´í•œ ë¶„ì–‘ê°€ ë¶„ì„ ê·¼ê±°\n- {fkp} ë“± ì£¼ê±° ë§Œì¡±ë„ 1ìœ„ì˜ ì§„ì§œ ì´ìœ \n\në°ì´í„°ëŠ” ê±°ì§“ë§ì„ í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì§ì ‘ í™•ì¸í•´ ë³´ì‹œê³  ê°€ì¹˜ë¥¼ íŒë‹¨í•˜ì‹­ì‹œì˜¤. ğŸ’\n\nâ–¶ ë¦¬í¬íŠ¸ ì‹ ì²­: [ìƒë‹´ì˜ˆì•½ì‹ ì²­]"
    ]

    return RegenerateCopyResponse(
        lms_copy_samples=lms_samples,
        channel_talk_samples=channel_samples
    )

@app.post("/analyze")
async def analyze_site(request: Optional[AnalyzeRequest] = None):
    """Gemini AIë¥¼ ì‚¬ìš©í•œ í˜„ì¥ ì •ë°€ ë¶„ì„ API (ê³ ë„í™” ë²„ì „)"""
    logger.info(f">>> Analyze request received: {request.field_name if request else 'No request body'}")
    try:
        req = request if request else AnalyzeRequest()
        
        field_name = getattr(req, 'field_name', "ë¶„ì„ í˜„ì¥")
        address = getattr(req, 'address', "ì§€ì—­ ì •ë³´ ì—†ìŒ")
        product_category = getattr(req, 'product_category', "ì•„íŒŒíŠ¸")
        sales_price = float(req.sales_price or 0.0)
        target_price = float(req.target_area_price or 0.0)
        
        # ê¸°ë³¸ ë³€ìˆ˜ ë¯¸ë¦¬ ê³„ì‚° (í”„ë¡¬í”„íŠ¸ ë° Fallback ê³µìš©)
        market_gap = target_price - sales_price
        gap_status = "ì €ë ´" if market_gap > 0 else "ë†’ì€"
        gap_percent = abs(round((market_gap / (sales_price if sales_price > 0 else 1)) * 100, 1))
        
        # supply_volume ì²˜ë¦¬
        try:
            supply_volume = int(req.supply_volume or 0)
        except:
            supply_volume = 0
            
        main_concern = req.main_concern or "ê¸°íƒ€"
        field_keypoints = getattr(req, 'field_keypoints', "")
        dp = str(req.down_payment) if req.down_payment else "10%"
        ib = req.interest_benefit or "ë¬´ì´ì"
        fkp = field_keypoints if field_keypoints else "íƒì›”í•œ ì…ì§€ì™€ ë¯¸ë˜ê°€ì¹˜"
        
        # 1. ì‹¤ì‹œê°„ ì—¬ë¡  ë° ë°ì´í„° ìˆ˜ì§‘
        search_context = ""
        try:
            async with httpx.AsyncClient() as client:
                search_url = "https://search.naver.com/search.naver"
                search_params = {"query": f"{field_name} ë¶„ì–‘ê°€ ëª¨ë¸í•˜ìš°ìŠ¤", "where": "view"}
                h = {"User-Agent": "Mozilla/5.0"}
                res = await client.get(search_url, params=search_params, headers=h, timeout=4.0)
                if res.status_code == 200:
                    search_context = res.text[:3000]
        except Exception as e:
            logger.warning(f"Live search skipped: {e}")

        # 2. AI ë¶„ì„ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ì‘ì„±
        prompt = f"""
        ë‹¹ì‹ ì€ ìƒìœ„ 1% ë¶€ë™ì‚° ë§ˆì¼€íŒ… ì „ë¬¸ê°€ì…ë‹ˆë‹¤. [{field_name}] í˜„ì¥ì˜ í•„ìŠ¹ ì „ëµì„ JSONìœ¼ë¡œ ì‘ì„±í•˜ì‹­ì‹œì˜¤.
        
        [í˜„ì¥ ì •ë³´]
        í˜„ì¥: {field_name} / ìœ„ì¹˜: {address} / ìƒí’ˆ: {product_category}
        ê°€ê²©: ìš°ë¦¬ {sales_price} VS ì£¼ë³€ {target_price}
        íŠ¹ì§•: {field_keypoints} / ê³ ë¯¼: {main_concern}
        
        [ê²€ìƒ‰ì°¸ê³ ] {search_context[:1000] if search_context else "ê²€ìƒ‰ ë°ì´í„° ì—†ìŒ"}
        
        [ì¶œë ¥ ê·œê²©]
        ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ì„ ìœ ì§€í•˜ë˜, ë‚´ìš©ì€ ì‹¤ì œ ì „ë¬¸ê°€ì²˜ëŸ¼ ì•„ì£¼ ìƒì„¸í•˜ê²Œ ì‘ì„±í•˜ì‹­ì‹œì˜¤. 
        ì ˆëŒ€ "ì‹œì¥ ê²½ìŸë ¥ì´ ì¶©ë¶„í•˜ë‹¤"ëŠ” ì‹ì˜ ì§§ì€ ë‹µë³€ì€ ê¸ˆì§€í•©ë‹ˆë‹¤.
        
        {{
            "market_diagnosis": "ìµœì†Œ 3ë¬¸ì¥ ì´ìƒì˜ ì‹¬ì¸µ ì‹œì¥ ë¶„ì„",
            "target_persona": "êµ¬ì²´ì ì¸ íƒ€ì¼“ ê³ ê° ìƒí™œìƒ ì •ì˜",
            "target_audience": ["#íƒœê·¸1", "#íƒœê·¸2", "#íƒœê·¸3", "#íƒœê·¸4", "#íƒœê·¸5"],
            "competitors": [
                {{"name": "ê²½ìŸë‹¨ì§€A", "price": {target_price}, "distance": "1.0km"}},
                {{"name": "ê²½ìŸë‹¨ì§€B", "price": {target_price * 1.1 if target_price > 0 else sales_price * 1.1:.0f}, "distance": "2.5km"}}
            ],
            "ad_recommendation": "êµ¬ì²´ì ì¸ ë§¤ì²´ ì§‘í–‰ ë¹„ì¤‘ê³¼ ì´ìœ ",
            "copywriting": "í›„í‚¹ ë„˜ì¹˜ëŠ” ë©”ì¸ ì¹´í”¼",
            "keyword_strategy": ["í‚¤ì›Œë“œ1", "2", "3", "4", "5"],
            "weekly_plan": ["1ì£¼ ì•¡ì…˜", "2ì£¼ ì•¡ì…˜", "3ì£¼ ì•¡ì…˜", "4ì£¼ ì•¡ì…˜"],
            "roi_forecast": {{"expected_leads": 130, "expected_cpl": 45000, "conversion_rate": 3.5}},
            "lms_copy_samples": [
                "ã€{{field_name}}ã€‘\\n\\nğŸ”¥ íŒŒê²©ì¡°ê±´ë³€ê²½!!\\nâ˜› ê³„ì•½ê¸ˆ {{down_payment}}\\nâ˜› {{interest_benefit}} íŒŒê²© í˜œíƒ\\nâ˜› ì‹¤ê±°ì£¼ì˜ë¬´ ë° ì²­ì•½í†µì¥ ç„¡\\n\\nâ–  ì´ˆí˜„ëŒ€ì  ì…ì§€+íŠ¸ë¦¬í”Œ êµí†µë§\\nğŸš… GTX ë° ì£¼ìš” ë…¸ì„  ì—°ì¥ ìˆ˜í˜œ(ì˜ˆì •)\\nğŸ« ë‹¨ì§€ ë°”ë¡œ ì• ì´ˆÂ·ì¤‘Â·ê³  ë„ë³´ í•™ì„¸ê¶Œ\\nğŸ™ï¸ {{address}} í•µì‹¬ ì¸í”„ë¼ ì›ìŠ¤í†± ë¼ì´í”„\\n\\nâ–  ë¸Œëœë“œ & ìì‚° ê°€ì¹˜\\nâ–¶ ì£¼ë³€ ì‹œì„¸ ëŒ€ë¹„ {gap_percent}% ë‚®ì€ ì••ë„ì  ë¶„ì–‘ê°€\\nâ–¶ {{field_keypoints}} íŠ¹í™” ì„¤ê³„ ì ìš©\\nâ–¶ ëŒ€ë‹¨ì§€ í”„ë¦¬ë¯¸ì—„ ëœë“œë§ˆí¬ ìŠ¤ì¼€ì¼\\n\\nğŸ ì˜ˆì•½ í›„ ë°©ë¬¸ ì‹œ 'ì‹ ì„¸ê³„ ìƒí’ˆê¶Œ' ì¦ì •\\nğŸ‰ ê³„ì•½ ì‹œ 'ê³ ê¸‰ ê°€ì „ ì‚¬ì€í’ˆ' íŠ¹ë³„ ì¦ì •\\nâ˜ï¸ ë¬¸ì˜ : 1600-0000",
                "[íŠ¹ë³„ê³µì‹ë°œì†¡] {{field_name}} ê´€ì‹¬ê³ ê° ì•ˆë‚´\\n(ì „ì„¸ëŒ€ ì„ í˜¸ë„ ë†’ì€ 84ã¡ ìœ„ì£¼ êµ¬ì„±)\\n\\nğŸ’° ê°•ë ¥í•œ ê¸ˆìœµ í˜œíƒ\\nâœ… ê³„ì•½ê¸ˆ {{down_payment}} (1ì°¨)\\nâœ… ì¤‘ë„ê¸ˆ 60% {{interest_benefit}}\\nâœ… ë¬´ì œí•œ ì „ë§¤ ê°€ëŠ¥ ë‹¨ì§€\\n\\nğŸ¡ í˜„ì¥ íŠ¹ì¥ì \\n- {{address}} ë‚´ ë§ˆì§€ë§‰ ë…¸ë‹¤ì§€ í•µì‹¬ ì…ì§€\\n- {gap_percent}% ì´ìƒì˜ í™•ì‹¤í•œ ì‹œì„¸ ì°¨ìµ ê¸°ëŒ€\\n- {{field_keypoints}} ë“± ê³ í’ˆê²© ì»¤ë®¤ë‹ˆí‹° ì‹œì„¤\\n- ë„ë³´ê¶Œ ëª…í’ˆ í•™ì›ê°€ ë° ëŒ€í˜• ë§ˆíŠ¸ ì¸ì ‘\\n\\në” ì´ìƒ ë§ì„¤ì´ì§€ ë§ˆì„¸ìš”. ë§ˆì§€ë§‰ ë¡œì—´ì¸µì´ ì†Œì§„ ì¤‘ì…ë‹ˆë‹¤.\\nâ˜ï¸ ìƒë‹´ë¬¸ì˜: 010-0000-0000",
                "ğŸš¨ {{field_name}} ì œë¡œê³„ì•½ê¸ˆ ìˆ˜ì¤€ ë§ˆê° ì„ë°•!\\n\\nğŸ”¥ ì „ì„¸ëŒ€ ì˜êµ¬ ì¡°ë§ ë° í”„ë¦¬ë¯¸ì—„ íŠ¹í™” ì„¤ê³„\\nğŸ”¥ í˜„ì¬ 84íƒ€ì… ì™„íŒ ì§ì „, ì”ì—¬ ì†Œìˆ˜ ë¶„ì–‘\\nğŸ”¥ {{interest_benefit}}, ì£¼íƒìˆ˜ ë¯¸í¬í•¨ ìˆ˜í˜œ ë‹¨ì§€\\n\\nğŸš— ì‚¬í†µíŒ”ë‹¬ êµí†µë§ í™•ì • ë° ì„œìš¸ ì ‘ê·¼ì„± í˜ì‹ \\nğŸï¸ ëŒ€í˜• ê³µì›ê³¼ ìˆ˜ë³€ ì¡°ë§ì„ í’ˆì€ ìˆ²ì„¸ê¶Œ/ë¬¼ì„¸ê¶Œ\\nğŸ—ï¸ ì¸ì ‘ ëŒ€ê·œëª¨ ê°œë°œ í˜¸ì¬ë¡œ ì¸í•œ ë¯¸ë˜ ê°€ì¹˜ ê¸‰ìƒìŠ¹\\n\\nğŸ ì„ ì°©ìˆœ ê³„ì•½ì¶•í•˜ ì´ë²¤íŠ¸ ì§„í–‰ ì¤‘\\nì˜ˆì•½ ë°©ë¬¸ë§Œ í•´ë„ 'ê³ ê¸‰ ì™€ì¸ ë° ì‚¬ì€í’ˆ' ì¦ì •\\nğŸ“ ëŒ€í‘œë²ˆí˜¸: 1811-0000"
            ],
            "channel_talk_samples": [
                "ğŸ”¥ {{field_name}} | íŒŒê²© ì¡°ê±´ë³€ê²½ ì†Œì‹!\\n\\ní˜„ì¬ í˜¸ê°±ë…¸ë…¸ì—ì„œ ê°€ì¥ ëœ¨ê±°ìš´ ê´€ì‹¬ì„ ë°›ëŠ” ì´ìœ , ë“œë””ì–´ ê³µê°œí•©ë‹ˆë‹¤! ğŸ’\\n\\nâœ… í•µì‹¬ í˜œíƒ ìš”ì•½:\\n- ê³„ì•½ê¸ˆ {{down_payment}} (ì…ì£¼ ì „ ì „ë§¤ ê°€ëŠ¥)\\n- ê¸ˆë¦¬ ê±±ì • ì—†ëŠ” {{interest_benefit}} í˜œíƒ í™•ì •\\n- ì¸ê·¼ ì‹œì„¸ ëŒ€ë¹„ {gap_percent}% ë‚®ì€ ì••ë„ì  ê²½ìŸë ¥\\n\\n'ì´ ê°€ê²©ì— ì´ êµí†µë§ì´ ì •ë§ì¸ê°€ìš”?' ë¼ëŠ” ë¬¸ì˜ê°€ ë¹—ë°œì¹˜ê³  ìˆìŠµë‹ˆë‹¤. ğŸš… GTX-D ë“± ê´‘ì—­ êµí†µë§ì˜ ìµœì¤‘ì‹¬, {{address}}ì˜ ìì¡´ì‹¬ì„ ì§€ê¸ˆ ë°”ë¡œ ì„ ì í•˜ì‹­ì‹œì˜¤.\\n\\nğŸ“¢ ì‹¤ì‹œê°„ ë¡œì—´ì¸µ ì”ì—¬ ìˆ˜ëŸ‰ í™•ì¸ ë° ì…ì§€ ë¶„ì„ ë¦¬í¬íŠ¸ ì‹ ì²­í•˜ê¸° ğŸ‘‡\\nâ˜ï¸ ëŒ€í‘œë¬¸ì˜ : 1600-0000",
                "ğŸš¨ [ê¸´ê¸‰] {{field_name}} ë¡œì—´ì¸µ ì„ ì°©ìˆœ ë§ˆê° ì§ì „!\\n\\në§ì„¤ì´ëŠ” ìˆœê°„ ê¸°íšŒëŠ” ì§€ë‚˜ê°‘ë‹ˆë‹¤. í˜„ì¬ {{field_name}} í˜„ì¥ì€ ë°©ë¬¸ê° í­ì£¼ë¡œ ì¸í•´ ë‚¨ì€ ë¬¼ëŸ‰ì´ ì‹¤ì‹œê°„ìœ¼ë¡œ ì§€ì›Œì§€ê³  ìˆìŠµë‹ˆë‹¤! ğŸ’¨\\n\\nğŸ’ ì™œ ì§€ê¸ˆ {{field_name}}ì¸ê°€?\\n1. {{address}} ë‚´ ë§ˆì§€ë§‰ í”„ë¦¬ë¯¸ì—„ ì…ì§€\\n2. ì‹œì„¸ ì°¨ìµë§Œ {gap_percent}% ì˜ˆìƒë˜ëŠ” í™•ì‹¤í•œ íˆ¬ìê°€ì¹˜\\n3. {{field_keypoints}} ë“± ë‹¨ì§€ ë‚´ ê³ í’ˆê²© íŠ¹í™” ì‹œì„¤\\n\\nì§€ê¸ˆ ë°”ë¡œ ìƒë‹´ ì˜ˆì•½í•˜ì‹œë©´ ëª¨ë¸í•˜ìš°ìŠ¤ ëŒ€ê¸° ì—†ëŠ” 'ìš°ì„  ì…ì¥ê¶Œ'ê³¼ 'íŠ¹ë³„ ì‚¬ì€í’ˆ'ì„ í•¨ê»˜ ë³´ë‚´ë“œë¦½ë‹ˆë‹¤. ğŸ\\n\\nğŸ“ ê¸´ê¸‰ ìƒë‹´ ë° ë°©ë¬¸ì˜ˆì•½: 010-0000-0000",
                "ğŸ“Š {{field_name}} ê³ ê´€ì—¬ ìœ ì € ì „ìš© [ì…ì§€ ë¶„ì„ ë³´ê³ ì„œ] ë°°í¬\\n\\ní˜¸ê°±ë…¸ë…¸ ì‹¤ìˆ˜ìš”ìë¶„ë“¤ì´ ì£¼ëª©í•˜ëŠ” ì§„ì§œ íŒ©íŠ¸ë¥¼ ë¶„ì„í–ˆìŠµë‹ˆë‹¤. ğŸ§\\në‹¨ìˆœ í™ë³´ë¬¼ì´ ì•„ë‹Œ, í•™êµ°/ìƒê¶Œ/ë¯¸ë˜ê°€ì¹˜ë¥¼ ìˆ«ìë¡œ ì¦ëª…í•œ ìœ ë£Œê¸‰ ì •ë°€ ë¦¬í¬íŠ¸ë¥¼ ë¬´ë£Œë¡œ ì œê³µí•©ë‹ˆë‹¤.\\n\\nâœ¨ ë¦¬í¬íŠ¸ ì£¼ìš” ë‚´ìš©:\\n- {{address}} ê¶Œì—­ í–¥í›„ 5ë…„ ë‚´ ìˆ˜ê¸‰ ë¶„ì„\\n- {gap_percent}% ì‹œì„¸ ì°¨ìµì´ ë°œìƒí•˜ëŠ” êµ¬ì²´ì  ê·¼ê±°\\n- ì‹¤ê±°ì£¼ìê°€ ê·¹ì°¬í•œ {{field_keypoints}} ë¶„ì„\\n\\në°ì´í„°ë¡œ ì¦ëª…ëœ í˜„ì¥, ì§ì ‘ ë¹„êµí•´ ë³´ì‹œê³  ê²°ì •í•˜ì‹­ì‹œì˜¤. ì˜¤ì§ ì±„ë„í†¡ ìœ ì… ê³ ê°ë‹˜ê»˜ë§Œ ìš°ì„  ê³µê°œí•©ë‹ˆë‹¤. ğŸ’\\n\\nâ–¶ ë¦¬í¬íŠ¸ ì‹ ì²­: [ìƒë‹´ì˜ˆì•½ì‹ ì²­]"
            ]
        }}
        """

        # 3. Gemini ëª¨ë¸ ì‹œë„ (ìœ ë£Œ í‚¤ ê°€ìš© ëª¨ë¸ ìš°ì„  ìˆœìœ„ ì¡°ì •)
        ai_data = None
        # ìœ ë£Œ ê³„ì •ì—ì„œ ì„ í˜¸ë˜ëŠ” 2.0 ë° latest ëª¨ë¸ ìš°ì„  ì‹œë„
        model_candidates = [
            'models/gemini-2.0-flash', 
            'models/gemini-1.5-flash', 
            'models/gemini-flash-latest',
            'models/gemini-1.5-pro',
            'models/gemini-pro-latest'
        ]
        
        for model_name in model_candidates:
            try:
                logger.info(f"Attempting AI analysis with model: {model_name}")
                model = genai.GenerativeModel(model_name)
                response = model.generate_content(prompt)
                if response and response.text:
                    ai_data = extract_json(response.text)
                    if ai_data: 
                        logger.info(f"Success with model: {model_name}")
                        break
            except Exception as e:
                logger.error(f"Model {model_name} failed: {e}")
                continue

        if not ai_data:
            logger.warning("AI model failed to provide valid JSON. Triggering Smart Local Engine.")
            raise Exception("AI Response Parsing Failed")

        # í•„ìˆ˜ í•„ë“œ ëˆ„ë½ ë°©ì§€ ë° ê¸°ë³¸ê°’ ë³´ì •
        safe_data = {
            "market_diagnosis": ai_data.get("market_diagnosis") or "ë°ì´í„° ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤.",
            "target_audience": ai_data.get("target_audience") or ["ì‹¤ê±°ì£¼ì", "íˆ¬ìì"],
            "target_persona": ai_data.get("target_persona") or "ì•ˆì •ì  ìì‚° ì¦ì‹ì„ ë…¸ë¦¬ëŠ” ìˆ˜ìš”ì",
            "competitors": ai_data.get("competitors") or [],
            "ad_recommendation": ai_data.get("ad_recommendation") or "ë©”íƒ€ ë° ë„¤ì´ë²„ ê´‘ê³  ì§‘í–‰ ê¶Œì¥",
            "copywriting": ai_data.get("copywriting") or f"[{field_name}] ì§€ê¸ˆ ë°”ë¡œ ë§Œë‚˜ë³´ì„¸ìš”.",
            "keyword_strategy": ai_data.get("keyword_strategy") or [field_name, "ë¶„ì–‘ì •ë³´"],
            "weekly_plan": ai_data.get("weekly_plan") or ["1ì£¼ì°¨: ë§ˆì¼€íŒ… ê¸°íš"],
            "roi_forecast": ai_data.get("roi_forecast") or {"expected_leads": 100, "expected_cpl": 50000, "conversion_rate": 2.5, "expected_ctr": 1.8},
            "lms_copy_samples": ai_data.get("lms_copy_samples") or [],
            "channel_talk_samples": ai_data.get("channel_talk_samples") or []
        }
        # Ensure expected_ctr is present if roi_forecast was provided by AI but missing this field
        if "expected_ctr" not in safe_data["roi_forecast"]:
            safe_data["roi_forecast"]["expected_ctr"] = 1.8

        # ì ìˆ˜ ê³„ì‚° logic
        price_score = min(100, max(0, 100 - abs(sales_price - target_price) / (target_price if target_price > 0 else 1) * 100))
        location_score = 75 + random.randint(-5, 10)
        benefit_score = 70 + random.randint(-5, 10)
        total_score = int((price_score * 0.4 + location_score * 0.3 + benefit_score * 0.3))
        # gap_percentëŠ” ìœ„ì—ì„œ ë¯¸ë¦¬ ê³„ì‚°ë¨

        return {
            "score": int(total_score),
            "score_breakdown": {
                "price_score": int(price_score),
                "location_score": int(location_score),
                "benefit_score": int(benefit_score),
                "total_score": int(total_score)
            },
            "market_diagnosis": safe_data["market_diagnosis"],
            "market_gap_percent": round(market_gap_percent, 2),
            "price_data": [
                {"name": "ìš°ë¦¬ í˜„ì¥", "price": sales_price},
                {"name": "ì£¼ë³€ ì‹œì„¸", "price": target_price},
                {"name": "ì‹œì„¸ ì°¨ìµ", "price": abs(target_price - sales_price)}
            ],
            "radar_data": [
                {"subject": "ë¶„ì–‘ê°€", "A": int(price_score), "B": 70, "fullMark": 100},
                {"subject": "ë¸Œëœë“œ", "A": 85, "B": 75, "fullMark": 100},
                {"subject": "ë‹¨ì§€ê·œëª¨", "A": min(100, (supply_volume // 10) + 20), "B": 60, "fullMark": 100},
                {"subject": "ì…ì§€", "A": int(location_score), "B": 65, "fullMark": 100},
                {"subject": "ë¶„ì–‘ì¡°ê±´", "A": 80, "B": 50, "fullMark": 100},
                {"subject": "ìƒí’ˆì„±", "A": int(benefit_score), "B": 70, "fullMark": 100}
            ],
            "target_persona": safe_data["target_persona"],
            "target_audience": safe_data["target_audience"],
            "competitors": safe_data["competitors"],
            "ad_recommendation": safe_data["ad_recommendation"],
            "copywriting": safe_data["copywriting"],
            "keyword_strategy": safe_data["keyword_strategy"],
            "weekly_plan": safe_data["weekly_plan"],
            "roi_forecast": safe_data["roi_forecast"],
            "lms_copy_samples": safe_data["lms_copy_samples"],
            "channel_talk_samples": safe_data["channel_talk_samples"],
            "media_mix": [
                {"media": "ë©”íƒ€/ì¸ìŠ¤íƒ€", "feature": "ì •ë°€ íƒ€ì¼“íŒ…", "reason": "ê´€ì‹¬ì‚¬ ê¸°ë°˜ ë„ë‹¬", "strategy_example": "í˜œíƒ ê°•ì¡° ê´‘ê³ "},
                {"media": "ë„¤ì´ë²„", "feature": "ê²€ìƒ‰ ê¸°ë°˜", "reason": "êµ¬ë§¤ ì˜í–¥ ê³ ê° í™•ë³´", "strategy_example": "ì§€ì—­ í‚¤ì›Œë“œ ì ìœ "},
                {"media": "ì¹´ì¹´ì˜¤", "feature": "ëª¨ë¨¼íŠ¸ íƒ€ê²Ÿ", "reason": "ì§€ì—­ ê¸°ë°˜ ë…¸ì¶œ", "strategy_example": "ë°©ë¬¸ ìœ ë„"}
            ]
        }
    except Exception as e:
        import traceback
        err_detail = str(e)
        logger.error(f"Critical analyze error: {e}\n{traceback.format_exc()}")
        
        # Fallback ë³€ìˆ˜ (ì´ë¯¸ í•¨ìˆ˜ ìƒë‹¨ì—ì„œ ê³„ì‚°ë¨)
        
        # ìƒí’ˆêµ°ë³„ íŠ¹í™” ë©˜íŠ¸
        cat_msg = "ì£¼ê±° ì„ í˜¸ë„ê°€ ë†’ì€ ì•„íŒŒíŠ¸" if "ì•„íŒŒíŠ¸" in product_category else "ìˆ˜ìµí˜• ë¶€ë™ì‚°ìœ¼ë¡œì„œ ê°€ì¹˜ê°€ ë†’ì€ ìƒí’ˆ"
        
        # ì§€ëŠ¥í˜• ì‹œì¥ ì§„ë‹¨ ìƒì„±
        smart_diagnosis = (
            f"[{field_name}]ì€ ì¸ê·¼ ì‹œì„¸({target_price}ë§Œì›) ëŒ€ë¹„ ì•½ {gap_percent}% {gap_status}í•œ ê°€ê²©ëŒ€ë¡œ ì±…ì •ë˜ì–´ ì‹¤ê±°ì£¼ ë° íˆ¬ì ìˆ˜ìš”ì˜ ìœ ì…ì´ ë§¤ìš° ê°•ë ¥í•  ê²ƒìœ¼ë¡œ ì˜ˆì¸¡ë©ë‹ˆë‹¤. "
            f"íŠ¹íˆ {address} ë‚´ì—ì„œë„ {cat_msg}ë¡œ ë¶„ë¥˜ë˜ì–´ ì…ì§€ì  í¬ì†Œì„±ì´ ë‹ë³´ì´ë©°, {field_keypoints if field_keypoints else 'íƒì›”í•œ ì…ì§€'}ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì´ˆê¸° ë¶„ì–‘ë¥  80% ì´ìƒì„ ëª©í‘œë¡œ í•˜ëŠ” ê³µê²©ì ì¸ ë§ˆì¼€íŒ…ì´ ìœ íš¨í•œ ì‹œì ì…ë‹ˆë‹¤. "
            f"ì£¼ë³€ {product_category} ê³µê¸‰ëŸ‰ê³¼ ëŒ€ë¹„í•´ ë³´ì•˜ì„ ë•Œ ì‹œì„¸ ì°¨ìµ ì•½ {abs(market_gap):.0f}ë§Œì›ì˜ í”„ë¦¬ë¯¸ì—„ í™•ë³´ê°€ ê°€ëŠ¥í•˜ë¯€ë¡œ, ì´ë¥¼ í•µì‹¬ ì†Œêµ¬ì ìœ¼ë¡œ í•œ í¼í¬ë¨¼ìŠ¤ ê´‘ê³  ì§‘í–‰ì„ ì ê·¹ ê¶Œì¥í•©ë‹ˆë‹¤."
        )

        return {
            "score": 85,
            "score_breakdown": {
                "price_score": 90 if market_gap > 0 else 70,
                "location_score": 82,
                "benefit_score": 88,
                "total_score": 85
            },
            "market_diagnosis": smart_diagnosis,
            "market_gap_percent": round((market_gap / (sales_price if sales_price > 0 else 1)) * 100, 2),
            "price_data": [
                {"name": "ìš°ë¦¬ í˜„ì¥", "price": sales_price},
                {"name": "ì£¼ë³€ ì‹œì„¸", "price": target_price},
                {"name": "ì‹œì„¸ ì°¨ìµ", "price": abs(target_price - sales_price)}
            ],
            "radar_data": [
                {"subject": "ë¶„ì–‘ê°€", "A": 90 if market_gap > 0 else 72, "B": 70, "fullMark": 100},
                {"subject": "ë¸Œëœë“œ", "A": 85, "B": 75, "fullMark": 100},
                {"subject": "ë‹¨ì§€ê·œëª¨", "A": min(100, (supply_volume // 10) + 30), "B": 60, "fullMark": 100},
                {"subject": "ì…ì§€", "A": 80, "B": 65, "fullMark": 100},
                {"subject": "ë¶„ì–‘ì¡°ê±´", "A": 80, "B": 50, "fullMark": 100},
                {"subject": "ìƒí’ˆì„±", "A": 90, "B": 70, "fullMark": 100}
            ],
            "target_persona": f"{address} ì¸ê·¼ ì‹¤ê±°ì£¼ë¥¼ í¬ë§í•˜ëŠ” 3040 ë§ë²Œì´ ë¶€ë¶€ ë° ì•ˆì •ì  ìì‚° ì¦ì‹ì„ ë…¸ë¦¬ëŠ” 50ëŒ€ íˆ¬ìì",
            "target_audience": ["#ë‚´ì§‘ë§ˆë ¨", "#ì‹¤ìˆ˜ìš”ì", f"#{address.split()[0] if address and address.split() else 'ë¶„ì–‘'}", "#í”„ë¦¬ë¯¸ì—„", "#ë¶„ì–‘ì •ë³´"],
            "competitors": [
                {"name": "ì¸ê·¼ ë¹„êµ ë‹¨ì§€ A", "price": target_price, "distance": "1.1km"},
                {"name": "ì¸ê·¼ ë¹„êµ ë‹¨ì§€ B", "price": round(target_price * 1.05), "distance": "2.3km"}
            ],
            "ad_recommendation": "ë„¤ì´ë²„ ë¸Œëœë“œê²€ìƒ‰ì„ í†µí•œ ì‹ ë¢°ë„ í™•ë³´ì™€ ë©”íƒ€/ì¸ìŠ¤íƒ€ì˜ 'ì‹œì„¸ì°¨ìµ' ê°•ì¡° ë¦¬ë“œê´‘ê³  ë¹„ì¤‘ 7:3 ì§‘í–‰ ê¶Œì¥",
            "copywriting": f"[{field_name}] ì£¼ë³€ ì‹œì„¸ë³´ë‹¤ {gap_percent}% ë” ê°€ë³ê²Œ! ë§ˆí¬ì˜ ìƒˆë¡œìš´ ì¤‘ì‹¬ì„ ì„ ì í•˜ì‹­ì‹œì˜¤.",
            "keyword_strategy": [field_name, f"{field_name} ë¶„ì–‘ê°€", f"{address.split()[0]} ì‹ ì¶•ì•„íŒŒíŠ¸", "ì²­ì•½ì¼ì •", "ëª¨ë¸í•˜ìš°ìŠ¤ìœ„ì¹˜"],
            "weekly_plan": [
                "1ì£¼: í‹°ì§• ê´‘ê³  ë° ê´€ì‹¬ê³ ê° DB 300ê±´ í™•ë³´ ëª©í‘œ",
                "2ì£¼: ë¶„ì–‘ê°€ ë° í˜œíƒ ê°•ì¡° ì •ë°€ íƒ€ê²ŸíŒ… ìº í˜ì¸ í™•ì‚°",
                "3ì£¼: ëª¨ë¸í•˜ìš°ìŠ¤ ë°©ë¬¸ ì˜ˆì•½ ì´ë²¤íŠ¸ ë° ì§‘ì¤‘ DB ê´€ë¦¬",
                "4ì£¼: ì²­ì•½ ì „ ë§ˆê° ì…ë°• ë©”ì‹œì§€ ë° ìµœì¢… ìƒë‹´ ì „í™˜ í™œë™"
            ],
            "roi_forecast": {"expected_leads": 120, "expected_cpl": 48000, "expected_ctr": 1.7, "conversion_rate": 3.2},
            "lms_copy_samples": [
                f"ã€{field_name}ã€‘\n\nğŸ”¥ íŒŒê²©ì¡°ê±´ë³€ê²½!!\nâ˜› ê³„ì•½ê¸ˆ 10%\nâ˜› ì¤‘ë„ê¸ˆ ë¬´ì´ì í˜œíƒ í™•ì •\nâ˜› ì‹¤ê±°ì£¼ì˜ë¬´ ë° ì „ë§¤ì œí•œ í•´ì œ\n\nâ–  ì´ˆíŠ¹ê¸‰ ì…ì§€+ê´‘ì—­ êµí†µë§ í™•ë³´\nğŸš… GTX ìˆ˜í˜œ ë° ì§€í•˜ì²  ì—°ì¥(ì˜ˆì •) ìˆ˜í˜œì§€\nğŸ« ë‹¨ì§€ ë°”ë¡œ ì• ì´ˆÂ·ì¤‘Â·ê³  í•™ì„¸ê¶Œ\nğŸ™ï¸ {address} ì¤‘ì‹¬ ìƒê¶Œ ë° ìƒí™œ ì¸í”„ë¼ ì™„ë¹„\n\nâ–  ë¸Œëœë“œ & ìì‚° ê°€ì¹˜\nâ–¶ ì£¼ë³€ ì‹œì„¸ ëŒ€ë¹„ {gap_percent}% ë‚®ì€ ì••ë„ì  ë¶„ì–‘ê°€\nâ–¶ {field_keypoints if field_keypoints else 'í”„ë¦¬ë¯¸ì—„ íŠ¹í™” ì„¤ê³„'} ì ìš©\nâ–¶ {supply_volume}ì„¸ëŒ€ ëœë“œë§ˆí¬ ìŠ¤ì¼€ì¼\n\nğŸ ì˜ˆì•½ ë°©ë¬¸ ì‹œ 'ì‹ ì„¸ê³„ ìƒí’ˆê¶Œ' ì¦ì •\nğŸ‰ ê³„ì•½ ì‹œ 'ê³ ê¸‰ ê°€ì „ ì‚¬ì€í’ˆ' íŠ¹ë³„ ì¦ì •\nâ˜ï¸ ê³µì‹ë¬¸ì˜ : 1600-0000",
                f"[ê³µì‹ë³¸ë¶€ë°œì†¡] {field_name} ë¡œì—´ì¸µ ì„ ì°©ìˆœ ì•ˆë‚´\n(ì „ì„¸ëŒ€ ì„ í˜¸ë„ ë†’ì€ {product_category} êµ¬ì„±)\n\nğŸ’° ê°•ë ¥í•œ ê¸ˆìœµ í˜œíƒ\nâœ… ê³„ì•½ê¸ˆ ì •ì•¡ì œ ì‹¤ì‹œ\nâœ… ì¤‘ë„ê¸ˆ 60% ì „ì•¡ ë¬´ì´ì\nâœ… ì‹¤ê±°ì£¼ì˜ë¬´ ç„¡ / ë¬´ì œí•œ ì „ë§¤ ê°€ëŠ¥\n\nğŸ¡ í˜„ì¥ íŠ¹ì¥ì \n- {address} ë‚´ ë§ˆì§€ë§‰ ë…¸ë‹¤ì§€ í•µì‹¬ í™©ê¸ˆ ìë¦¬\n- ì‹œì„¸ ì°¨ìµë§Œ ì•½ {abs(market_gap):.0f}ë§Œì›ì˜ ê°•ë ¥í•œ ê°€ì¹˜\n- ë„ë³´ê¶Œ ëª…í’ˆ í•™êµ° ë° ëŒ€ë‹¨ì§€ í”„ë¦¬ë¯¸ì—„ ì»¤ë®¤ë‹ˆí‹°\n- {field_keypoints if field_keypoints else 'ì…ì£¼ë¯¼ ì „ìš© íŠ¹í™” ì„œë¹„ìŠ¤'}\n\nê³ ë¯¼í•˜ì‹œëŠ” ì‚¬ì´ ë§ˆì§€ë§‰ ë¡œì—´ì¸µì´ ë¹ ë¥´ê²Œ ì†Œì§„ ì¤‘ì…ë‹ˆë‹¤.\nâ˜ï¸ ëŒ€í‘œë²ˆí˜¸: 010-0000-0000",
                f"ğŸš¨ {field_name} ì œë¡œê³„ì•½ê¸ˆ ìˆ˜ì¤€ ë§ˆê° ì„ë°• ì•ˆë‚´!\n\nğŸ”¥ ì „ì„¸ëŒ€ ì˜êµ¬ íŒŒë…¸ë¼ë§ˆ ì¡°ë§ ë° ë‚¨í–¥ ë°°ì¹˜\nğŸ”¥ í˜„ì¬ ì¸ê¸° íƒ€ì… ì™„íŒ ì§ì „, ì†Œìˆ˜ ì”ì—¬ ë¶„ì–‘\nğŸ”¥ ì·¨ë“ì„¸ ì¤‘ê³¼ ë°°ì œ ë° ì£¼íƒìˆ˜ ë¯¸í¬í•¨ ìˆ˜í˜œ\n\nğŸš— ê´‘ì—­ êµí†µë§ í™•ì •ìœ¼ë¡œ ì„œìš¸ ë° íŒêµ 20ë¶„ëŒ€\nğŸï¸ ë‹¨ì§€ ì• ëŒ€í˜• ê³µì›ì„ í’ˆì€ ì™„ë²½í•œ ìˆ²ì„¸ê¶Œ ë¼ì´í”„\nğŸ—ï¸ ì¸ì ‘ ëŒ€ê·œëª¨ ì •ë¹„ì‚¬ì—…ìœ¼ë¡œ ì…ì£¼ ì‹œ ê°€ì¹˜ í­ë“±\n\nğŸ ì„ ì°©ìˆœ ê³„ì•½ì¶•í•˜ ì´ë²¤íŠ¸ 'í™©ê¸ˆì—´ì‡ ' ì¦ì • ì¤‘\nìƒë‹´ ì˜ˆì•½ë§Œ í•´ë„ 'ì‚¬ì€í’ˆ' 100% ì¦ì •\nğŸ“ ê¸´ê¸‰ë¬¸ì˜: 1800-0000"
            ],
            "channel_talk_samples": [
                f"ğŸ”¥ {field_name} | íŒŒê²© ì¡°ê±´ë³€ê²½ ì†Œì‹!\n\ní˜„ì¬ í˜¸ê°±ë…¸ë…¸ ìœ ì €ë“¤ì´ ê°€ì¥ ì£¼ëª©í•˜ëŠ” í˜„ì¥, ì´ìœ ê°€ ìˆìŠµë‹ˆë‹¤! ğŸ’\n\nâœ… í•µì‹¬ í˜œíƒ ìš”ì•½:\n- ê³„ì•½ ì´ˆê¸° ìê¸ˆ ë¶€ë‹´ ì™„í™”\n- ì´ìå¿ƒé… ì—†ëŠ” {ib} í˜œíƒ í™•ì•½\n- ì¸ê·¼ ì‹œì„¸ ëŒ€ë¹„ {gap_percent}% ë‚®ì€ ì••ë„ì  ê°€ê²© ë©”ë¦¬íŠ¸\n\nğŸš… {address}ì˜ í•µì‹¬ ì¸í”„ë¼ë¥¼ ëª¨ë‘ ëˆ„ë¦¬ëŠ” ë§ˆì§€ë§‰ ê¸°íšŒ. 'ì´ ê°€ê²©ì— ì´ ì…ì§€ê°€ ê°€ëŠ¥í•´?'ë¼ëŠ” ë°ì´í„°ì˜ ê°€ì¹˜ë¥¼ ì§ì ‘ í™•ì¸í•˜ì‹­ì‹œì˜¤.\n\nğŸ“¢ ì”ì—¬ ì„¸ëŒ€ í™•ì¸ ë° ë¶„ì„ ë¦¬í¬íŠ¸ ì‹ ì²­ ğŸ‘‡\nâ˜ï¸ ëŒ€í‘œë¬¸ì˜ : 1600-0000",
                f"ğŸš¨ [ê¸´ê¸‰] {field_name} ë¡œì—´ì¸µ ì„ ì°©ìˆœ ë§ˆê° 5ë¶„ ì „!\n\në§ì„¤ì´ëŠ” ìˆœê°„ ì‚¬ë¼ì§‘ë‹ˆë‹¤. í˜„ì¬ {field_name} í˜„ì¥ì€ ì‹¤ì‹œê°„ ê³„ì•½ í­ì£¼ë¡œ ë¡œì—´ì¸µ ìˆ˜ëŸ‰ì´ ê¸‰ê²©íˆ ì†Œì§„ ì¤‘ì…ë‹ˆë‹¤! ğŸ’¨\n\nğŸ’ íˆ¬ì/ì‹¤ê±°ì£¼ í¬ì¸íŠ¸:\n1. {address} ê¶Œì—­ ìµœìƒìœ„ ëœë“œë§ˆí¬ ì…ì§€\n2. ì‹œì„¸ ì°¨ìµë§Œ {gap_percent}% ì´ìƒ ì˜ˆìƒë˜ëŠ” ìˆ˜ìµì„±\n3. {field_keypoints if field_keypoints else 'í”„ë¦¬ë¯¸ì—„ ì£¼ê±° ë¼ì´í”„'} ì‹¤í˜„\n\nì§€ê¸ˆ ì˜ˆì•½ ë°©ë¬¸ ì‹œ ëŒ€ê¸° ì—†ì´ ê´€ëŒ ê°€ëŠ¥í•œ 'ìš°ì„  ì…ì¥ê¶Œ'ê³¼ 'ì‚¬ì€í’ˆ ì¦ì •ê¶Œ'ì„ ì¦‰ì‹œ ë°œê¸‰í•´ ë“œë¦½ë‹ˆë‹¤. ğŸ\n\nğŸ“ ê¸´ê¸‰ ìƒë‹´ ë¬¸ì˜: 010-0000-0000",
                f"ğŸ“Š {field_name} ê³ ê´€ì—¬ íƒ€ê²Ÿ ì „ìš© [íŒ©íŠ¸ ì²´í¬ ë¦¬í¬íŠ¸]\n\ní˜¸ê°±ë…¸ë…¸ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ëŠ” ì§„ì§œ ì…ì§€ ë°ì´í„°ë¥¼ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤. ğŸ§\ní•™êµ°, ìƒê¶Œ, ë¯¸ë˜ êµí†µ í˜¸ì¬ë¥¼ ìˆ˜ì¹˜ë¡œ ì¦ëª…í•œ ìœ ë£Œê¸‰ ì •ë°€ ë¦¬í¬íŠ¸ ë°°í¬ ì¤‘!\n\nâœ¨ ë¦¬í¬íŠ¸ ìˆ˜ë¡ ë‚´ìš©:\n- {address} ê¶Œì—­ 5ë…„ ë‚´ ê³µê¸‰ ì´ëŸ‰ ë¶„ì„\n- ì¸ê·¼ ëŒ€ë¹„ {gap_percent}% ë” ê°€ë²¼ìš´ ë¶„ì–‘ê°€ ë¶„ì„ ë°ì´í„°\n- ìì‚° ê°€ì¹˜ë¥¼ ë†’ì´ëŠ” {field_keypoints if field_keypoints else 'ì…ì§€ì  í¬ì†Œì„±'} ê·¼ê±°\n\nì˜¤ì§ ìœ„ ë¦¬í¬íŠ¸ë¥¼ ì‹ ì²­í•˜ì‹  ë¶„ê»˜ë§Œ ë¹„ê³µê°œ ì”ì—¬ ë¬¼ëŸ‰ ì •ë³´ë¥¼ ìš°ì„  ì œê³µí•©ë‹ˆë‹¤. ğŸ’\n\nâ–¶ ë¦¬í¬íŠ¸ ì‹ ì²­: [ìƒë‹´ì˜ˆì•½ì‹ ì²­]"
            ],
            "media_mix": [
                {"media": "ë©”íƒ€/ì¸ìŠ¤íƒ€", "feature": "ì •ë°€ íƒ€ì¼“íŒ…", "reason": "ê´€ì‹¬ì‚¬ ê¸°ë°˜ ë„ë‹¬", "strategy_example": "í˜œíƒ ê°•ì¡° ê´‘ê³ "},
                {"media": "ë„¤ì´ë²„", "feature": "ê²€ìƒ‰ ê¸°ë°˜", "reason": "êµ¬ë§¤ ì˜í–¥ ê³ ê° í™•ë³´", "strategy_example": "ì§€ì—­ í‚¤ì›Œë“œ ì ìœ "},
                {"media": "ì¹´ì¹´ì˜¤", "feature": "ëª¨ë¨¼íŠ¸ íƒ€ê²Ÿ", "reason": "ì§€ì—­ ê¸°ë°˜ ë…¸ì¶œ", "strategy_example": "ë°©ë¬¸ ìœ ë„"}
            ]
        }

@app.get("/import-csv")
async def import_csv_data():
    """CSV íŒŒì¼ì—ì„œ ë°ì´í„°ë¥¼ import"""
    import csv
    
    csv_file = "sites_data.csv"
    if not os.path.exists(csv_file):
        return {"status": "error", "message": "CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
    
    imported = 0
    updated = 0
    
    try:
        with open(csv_file, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            
            with Session(engine) as session:
                for row in reader:
                    site_id = row['id']
                    existing = session.get(Site, site_id)
                    
                    if existing:
                        existing.name = row['name']
                        existing.address = row['address']
                        existing.brand = row['brand'] if row['brand'] else None
                        existing.category = row['category']
                        existing.price = float(row['price'])
                        existing.target_price = float(row['target_price'])
                        existing.supply = int(row['supply'])
                        existing.status = row['status'] if row['status'] else None
                        updated += 1
                    else:
                        session.add(Site(
                            id=site_id,
                            name=row['name'],
                            address=row['address'],
                            brand=row['brand'] if row['brand'] else None,
                            category=row['category'],
                            price=float(row['price']),
                            target_price=float(row['target_price']),
                            supply=int(row['supply']),
                            status=row['status'] if row['status'] else None
                        ))
                        imported += 1
                session.commit()
        return {"status": "success", "imported": imported, "updated": updated}
    except Exception as e:
        logger.error(f"CSV import error: {e}")
        return {"status": "error", "message": str(e)}

class LeadSubmitRequest(BaseModel):
    name: str
    phone: str
    rank: str
    site: str
    source: Optional[str] = "ì•Œ ìˆ˜ ì—†ìŒ"

@app.post("/submit-lead")
async def submit_lead(req: LeadSubmitRequest):
    """ëª¨ìˆ˜ ì‹ ì²­(ë¦¬ë“œ) ì œì¶œ API"""
    try:
        with Session(engine) as session:
            new_lead = Lead(
                name=req.name,
                phone=req.phone,
                rank=req.rank,
                site=req.site,
                source=req.source
            )
            session.add(new_lead)
            session.commit()
            logger.info(f"New lead submitted: {req.name} ({req.site})")
            
            # êµ¬ê¸€ ì‹œíŠ¸ ì—°ë™ (ì›¹í›… URLì´ ì„¤ì •ëœ ê²½ìš°)
            if GOOGLE_SHEET_WEBHOOK_URL:
                try:
                    # êµ¬ê¸€ ë§¤í¬ë¡œëŠ” ë¦¬ë””ë ‰ì…˜ì„ ì‚¬ìš©í•˜ë¯€ë¡œ follow_redirects=Trueê°€ í•„ìˆ˜ì…ë‹ˆë‹¤.
                    async with httpx.AsyncClient(follow_redirects=True) as client:
                        payload = {
                            "timestamp": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                            "name": req.name,
                            "phone": req.phone,
                            "rank": req.rank,
                            "site": req.site,
                            "source": req.source
                        }
                        # ë°ì´í„°ê°€ í™•ì‹¤íˆ ì „ì†¡ë  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦½ë‹ˆë‹¤.
                        response = await client.post(GOOGLE_SHEET_WEBHOOK_URL, json=payload, timeout=8.0)
                        logger.info(f"Google Sheet webhook triggered. Status: {response.status_code}")
                except Exception as ex:
                    logger.error(f"Google Sheet sync error: {ex}")

        return {"status": "success", "message": "Lead submitted successfully"}
    except Exception as e:
        logger.error(f"Lead submission error: {e}")
        raise HTTPException(status_code=500, detail="ë¦¬ë“œ ì œì¶œ ì¤‘ ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
@app.get("/")
async def root():
    return {"message": "Bunyang AlphaGo API is running"}

if __name__ == "__main__":
    create_db_and_tables()
    port = int(os.environ.get("PORT", 8000))
    uvicorn.run("main:app", host="0.0.0.0", port=port, reload=True)
